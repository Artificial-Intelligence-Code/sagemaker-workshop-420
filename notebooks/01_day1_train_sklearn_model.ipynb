{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train a scikit-learn Model Using a Custom Training Script.\n",
    "\n",
    "* Goals:\n",
    "    * Walk through a basic example of training a custom model in a Studio Notebook.\n",
    "    * Introduce the `sagemaker.sklearn.estimator.SKLearn` class for handling end-to-end training custom Scikit-learn models.\n",
    "\n",
    "* Code adapted from the [scikit_learn_iris](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/scikit_learn_iris) sample notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup\n",
    "\n",
    "Change into the notebooks directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/sagemaker-workshop-420/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /root/sagemaker-workshop-420/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup S3 paths and local paths to use for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts will be written to s3://sagemaker-workshop-420/iris/ .\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'sagemaker-workshop-420'\n",
    "PREFIX = 'iris'\n",
    "\n",
    "LOCAL_DATA_DIRECTORY = f'../data/{PREFIX}'\n",
    "\n",
    "print(f\"Artifacts will be written to s3://{BUCKET}/{PREFIX}/ .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create boto3 Session, Sagemaker session and role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::209970524256:role/service-role/AmazonSageMaker-ExecutionRole-20200414T065516\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a dataset and upload to S3 for training\n",
    "\n",
    "We're using a sample of the classic [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is included with Scikit-learn. We will load the dataset, write it locally, then write the dataset to s3 to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset, then join labels and features\n",
    "iris = datasets.load_iris()\n",
    "joined_iris = np.insert(iris.data, 0, iris.target, axis=1)\n",
    "\n",
    "# Create directory and write csv\n",
    "os.makedirs(LOCAL_DATA_DIRECTORY, exist_ok=True)\n",
    "np.savetxt(f'{LOCAL_DATA_DIRECTORY}/iris.csv', joined_iris, delimiter=',',\n",
    "           fmt='%1.1f, %1.3f, %1.3f, %1.3f, %1.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data locally, we can use use the tools provided by the SageMaker Python SDK to upload the data to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sagemaker_session.upload_data(\n",
    "    f'{LOCAL_DATA_DIRECTORY}/iris.csv',\n",
    "    bucket=BUCKET,\n",
    "    key_prefix=PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a custom Scikit-learn script to train a model\n",
    "\n",
    "SageMaker can now run a scikit-learn script using the `SKLearn` estimator. When executed on SageMaker a number of helpful environment variables are available to access properties of the training environment, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to. Any artifacts saved in this folder are uploaded to S3 for model hosting after the training job completes.\n",
    "* `SM_OUTPUT_DIR`: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing two input channels, 'train' and 'test', were used in the call to the `SKLearn` estimator's `fit()` method, the following environment variables will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAIN`: A string representing the path to the directory containing data in the 'train' channel\n",
    "* `SM_CHANNEL_TEST`: Same as above, but for the 'test' channel.\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance. For example, the script that we will run in this notebook is the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#  \u001b[39;49;00m\n",
      "\u001b[37m#  Licensed under the Apache License, Version 2.0 (the \"License\").\u001b[39;49;00m\n",
      "\u001b[37m#  You may not use this file except in compliance with the License.\u001b[39;49;00m\n",
      "\u001b[37m#  A copy of the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#  \u001b[39;49;00m\n",
      "\u001b[37m#      http://www.apache.org/licenses/LICENSE-2.0\u001b[39;49;00m\n",
      "\u001b[37m#  \u001b[39;49;00m\n",
      "\u001b[37m#  or in the \"license\" file accompanying this file. This file is distributed \u001b[39;49;00m\n",
      "\u001b[37m#  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either \u001b[39;49;00m\n",
      "\u001b[37m#  express or implied. See the License for the specific language governing \u001b[39;49;00m\n",
      "\u001b[37m#  permissions and limitations under the License.\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m tree\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexternals\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m joblib\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Hyperparameters are described here. In this simple example we are just including one hyperparameter.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--max_leaf_nodes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=-\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Sagemaker specific arguments. Defaults are set in the environment variables.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    \u001b[37m# Take the set of files and read them all into a single pandas dataframe\u001b[39;49;00m\n",
      "    input_files = [ os.path.join(args.train, file) \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m os.listdir(args.train) ]\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(input_files) == \u001b[34m0\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m((\u001b[33m'\u001b[39;49;00m\u001b[33mThere are no files in \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m +\n",
      "                          \u001b[33m'\u001b[39;49;00m\u001b[33mThis usually indicates that the channel (\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m) was incorrectly specified,\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m +\n",
      "                          \u001b[33m'\u001b[39;49;00m\u001b[33mthe data specification in S3 was incorrectly specified or the role specified\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m +\n",
      "                          \u001b[33m'\u001b[39;49;00m\u001b[33mdoes not have permission to access the data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).format(args.train, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    raw_data = [ pd.read_csv(file, header=\u001b[34mNone\u001b[39;49;00m, engine=\u001b[33m\"\u001b[39;49;00m\u001b[33mpython\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m input_files ]\n",
      "    train_data = pd.concat(raw_data)\n",
      "\n",
      "    \u001b[37m# labels are in the first column\u001b[39;49;00m\n",
      "    train_y = train_data.ix[:,\u001b[34m0\u001b[39;49;00m]\n",
      "    train_X = train_data.ix[:,\u001b[34m1\u001b[39;49;00m:]\n",
      "\n",
      "    \u001b[37m# Here we support a single hyperparameter, 'max_leaf_nodes'. Note that you can add as many\u001b[39;49;00m\n",
      "    \u001b[37m# as your training my require in the ArgumentParser above.\u001b[39;49;00m\n",
      "    max_leaf_nodes = args.max_leaf_nodes\n",
      "\n",
      "    \u001b[37m# Now use scikit-learn's decision tree classifier to train the model.\u001b[39;49;00m\n",
      "    clf = tree.DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)\n",
      "    clf = clf.fit(train_X, train_y)\n",
      "\n",
      "    \u001b[37m# Print the coefficients of the trained classifier, and save the coefficients\u001b[39;49;00m\n",
      "    joblib.dump(clf, os.path.join(args.model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[33m\"\"\"Deserialized and return fitted model\u001b[39;49;00m\n",
      "\u001b[33m    \u001b[39;49;00m\n",
      "\u001b[33m    Note that this should have the same name as the serialized model in the main method\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    clf = joblib.load(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m clf\n"
     ]
    }
   ],
   "source": [
    "!pygmentize '../scripts/sklearn_iris.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Scikit-learn container imports your training script, you should always put your training code in a main guard `(if __name__=='__main__':)` so that the container does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For more information about training environment variables, please visit https://github.com/aws/sagemaker-containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create SageMaker Scikit Estimator\n",
    "\n",
    "To run our Scikit-learn training script on SageMaker, we construct a `sagemaker.sklearn.estimator.sklearn` estimator, which accepts several constructor arguments:\n",
    "\n",
    "* __entry_point__: The path to the Python script SageMaker runs for training and prediction.\n",
    "* __role__: Role ARN\n",
    "* __train_instance_type__ *(optional)*: The type of SageMaker instances for training. __Note__: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on Sagemaker.\n",
    "* __hyperparameters__ *(optional)*: A dictionary passed to the train function as hyperparameters.\n",
    "* __code_location__ *(optional)*: The S3 prefix URI where custom code will be uploaded\n",
    "* __output_path__ *(optional)*: S3 location for saving the training result (model artifacts and output files).\n",
    "\n",
    "To see the code for the SKLearn Estimator, see here: https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='../scripts/sklearn_iris.py',\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    code_location=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "    output_path=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={'max_leaf_nodes': 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit the SKLearn Estimator on Iris data\n",
    "\n",
    "Training is very simple, just call `fit` on the Estimator! This will start a SageMaker Training job that will download the data for us, invoke our scikit-learn code (in the provided script file), and save any model artifacts that the script creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-14 11:31:11 Starting - Starting the training job...\n",
      "2020-04-14 11:31:14 Starting - Launching requested ML instances...\n",
      "2020-04-14 11:32:11 Starting - Preparing the instances for training......\n",
      "2020-04-14 11:33:09 Downloading - Downloading input data...\n",
      "2020-04-14 11:33:34 Training - Downloading the training image..\u001b[34m2020-04-14 11:33:48,337 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:48,340 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:48,350 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:48,641 sagemaker-containers INFO     Module sklearn_iris does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:48,641 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:48,641 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:48,641 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn-iris\n",
      "  Building wheel for sklearn-iris (setup.py): started\n",
      "  Building wheel for sklearn-iris (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-iris: filename=sklearn_iris-1.0.0-py2.py3-none-any.whl size=7005 sha256=47f22725cd8f0457f3eed2869f48732a28313c99774098715db58d80398ff9c4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ev7bayzd/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn-iris\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sklearn-iris\u001b[0m\n",
      "\u001b[34mSuccessfully installed sklearn-iris-1.0.0\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:50,054 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:50,065 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max_leaf_nodes\": 30\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-04-14-11-31-11-701\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-workshop-420/iris/sagemaker-scikit-learn-2020-04-14-11-31-11-701/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sklearn_iris\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sklearn_iris.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"max_leaf_nodes\":30}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sklearn_iris.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sklearn_iris\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-workshop-420/iris/sagemaker-scikit-learn-2020-04-14-11-31-11-701/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"max_leaf_nodes\":30},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-04-14-11-31-11-701\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-workshop-420/iris/sagemaker-scikit-learn-2020-04-14-11-31-11-701/source/sourcedir.tar.gz\",\"module_name\":\"sklearn_iris\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sklearn_iris.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--max_leaf_nodes\",\"30\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEAF_NODES=30\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m sklearn_iris --max_leaf_nodes 30\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34m/opt/ml/code/sklearn_iris.py:48: FutureWarning: \u001b[0m\n",
      "\u001b[34m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[34m.loc for label based indexing or\u001b[0m\n",
      "\u001b[34m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[34mSee the documentation here:\u001b[0m\n",
      "\u001b[34mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  train_y = train_data.ix[:,0]\u001b[0m\n",
      "\u001b[34m/opt/ml/code/sklearn_iris.py:49: FutureWarning: \u001b[0m\n",
      "\u001b[34m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[34m.loc for label based indexing or\u001b[0m\n",
      "\u001b[34m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[34mSee the documentation here:\u001b[0m\n",
      "\u001b[34mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  train_X = train_data.ix[:,1:]\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:822: FutureWarning: \u001b[0m\n",
      "\u001b[34m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[34m.loc for label based indexing or\u001b[0m\n",
      "\u001b[34m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[34mSee the documentation here:\u001b[0m\n",
      "\u001b[34mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\u001b[0m\n",
      "\u001b[34m2020-04-14 11:33:51,380 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-14 11:34:09 Uploading - Uploading generated training model\n",
      "2020-04-14 11:34:09 Completed - Training job completed\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Head to the URL in the following cell to view the details of this training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://us-east-2.console.aws.amazon.com/sagemaker/home?region=us-east-2#/jobs'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"https://{region}.console.aws.amazon.com/sagemaker/home?region={region}#/jobs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:environment/datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
