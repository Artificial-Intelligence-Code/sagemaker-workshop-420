{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3. Use Experiments, Trials, and Search to Organize ML Experiments.\n",
    "\n",
    "* Goals\n",
    "    * Train Tensorflow and PyTorch models using custom training scripts.\n",
    "    * Organize training using `Experiments` and `Trials`.\n",
    "    * Use SageMaker Search functionality to find the best model.\n",
    "* Code adapted from the following sample notebooks:\n",
    "    * [tensorflow_script_mode_training_and_serving](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_script_mode_training_and_serving/tensorflow_script_mode_training_and_serving.ipynb)\n",
    "    * [pytorch_mnist](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/pytorch_mnist/pytorch_mnist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup\n",
    "\n",
    "Change into the notebooks directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/sagemaker-workshop-420/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /root/sagemaker-workshop-420/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts will be written to s3://sagemaker-workshop-420/mnist\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'sagemaker-workshop-420'\n",
    "PREFIX = 'mnist'\n",
    "\n",
    "LOCAL_DATA_DIRECTORY = f'../data/{PREFIX}'\n",
    "\n",
    "print(f\"Artifacts will be written to s3://{BUCKET}/{PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets create our Sagemaker session and role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::209970524256:role/service-role/AmazonSageMaker-ExecutionRole-20200414T065516\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "sagemaker_client = boto_session.client('sagemaker')\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session,\n",
    "                                      sagemaker_client=sagemaker_client)\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training a Tensorflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Data\n",
    "\n",
    "The MNIST dataset has been loaded to the public S3 buckets ``sagemaker-sample-data-<REGION>`` under the prefix ``tensorflow/mnist``. There are four ``.npy`` file under this prefix:\n",
    "* `train_data.npy`\n",
    "* `eval_data.npy`\n",
    "* `train_labels.npy`\n",
    "* `eval_labels.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-sample-data-us-east-2/tensorflow/mnist'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_uri = f's3://sagemaker-sample-data-{region}/tensorflow/mnist'\n",
    "training_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Training Script\n",
    "\n",
    "This tutorial's training script was adapted from TensorFlow's official [CNN MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py). We have modified it to handle the ``model_dir`` parameter passed in by SageMaker. This is an S3 path which can be used for data sharing during distributed training and checkpointing and/or model persistence. We have also added an argument-parsing function to handle processing training-related variables.\n",
    "\n",
    "At the end of the training job we have added a step to export the trained model to the path stored in the environment variable ``SM_MODEL_DIR``, which always points to ``/opt/ml/model``. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training.\n",
    "\n",
    "Here is the entire script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\n",
      "\u001b[37m# language governing permissions and limitations under the License.import tensorflow as tf\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel\u001b[39;49;00m(x_train, y_train, x_test, y_test):\n",
      "    \u001b[33m\"\"\"Generate a simple model\"\"\"\u001b[39;49;00m\n",
      "    model = tf.keras.models.Sequential([\n",
      "        tf.keras.layers.Flatten(),\n",
      "        tf.keras.layers.Dense(\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu),\n",
      "        tf.keras.layers.Dropout(\u001b[34m0.4\u001b[39;49;00m),\n",
      "        tf.keras.layers.Dense(\u001b[34m10\u001b[39;49;00m, activation=tf.nn.softmax)\n",
      "    ])\n",
      "\n",
      "    model.compile(optimizer=\u001b[33m'\u001b[39;49;00m\u001b[33madam\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  loss=\u001b[33m'\u001b[39;49;00m\u001b[33msparse_categorical_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    model.fit(x_train, y_train)\n",
      "    model.evaluate(x_test, y_test)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\n",
      "    \u001b[33m\"\"\"Load MNIST training data\"\"\"\u001b[39;49;00m\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\n",
      "    \u001b[33m\"\"\"Load MNIST testing data\"\"\"\u001b[39;49;00m\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    args, unknown = _parse_args()\n",
      "\n",
      "    train_data, train_labels = _load_training_data(args.train)\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\n",
      "\n",
      "    mnist_classifier = model(train_data, train_labels, eval_data, eval_labels)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\n",
      "        \u001b[37m# save model to an S3 directory with version number '00000001'\u001b[39;49;00m\n",
      "        mnist_classifier.save(os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33m000000001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mmy_model.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow 2.1 script\n",
    "!pygmentize '../scripts/tensorflow_mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Use Experiment to track experiment metadata\n",
    "\n",
    "#### Step 1 - Create an Experiment\n",
    "\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : \n",
    "\n",
    "1. a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or \n",
    "2. a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”),\n",
    "3. a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment = Experiment.create(\n",
    "    experiment_name=f\"TF-mnist-{int(time.time())}\", \n",
    "    description=\"Classification of mnist hand-written digits using tensorflow\", \n",
    "    sagemaker_boto_client=sagemaker_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f0779e00dd0>,experiment_name='TF-mnist-1586949006',description='Classification of mnist hand-written digits using tensorflow',experiment_arn='arn:aws:sagemaker:us-east-2:209970524256:experiment/tf-mnist-1586949006',response_metadata={'RequestId': '281b1d40-ad66-49c2-ba8a-196d3736fdbb', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '281b1d40-ad66-49c2-ba8a-196d3736fdbb', 'content-type': 'application/x-amz-json-1.1', 'content-length': '91', 'date': 'Wed, 15 Apr 2020 11:10:06 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "print(mnist_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Track Experiment using Trials\n",
    "\n",
    "Now create a Trial for each training run to track the it's inputs, parameters, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = f\"tensorflow-mnist-{int(time.time())}\"\n",
    "\n",
    "trial = Trial.create(\n",
    "    trial_name=trial_name, \n",
    "    experiment_name=mnist_experiment.experiment_name,\n",
    "    sagemaker_boto_client=sagemaker_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Initialize the Tensorflow Estimator\n",
    "\n",
    "The `sagemaker.tensorflow.TensorFlow` estimator handles locating the script mode container, uploading your script to a S3 location and creating a SageMaker training job. Let's call out a couple important parameters here:\n",
    "\n",
    "* `py_version` is set to `'py3'` to indicate that we are using script mode since legacy mode supports only Python 2. Though Python 2 will be deprecated soon, you can use script mode with Python 2 by setting `py_version` to `'py2'` and `script_mode` to `True`.\n",
    "* `enable_sagemaker_metrics` is set to `True` to capture metrics like `accuracy` and `loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator = TensorFlow(\n",
    "    entry_point='../scripts/tensorflow_mnist.py',\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p2.xlarge',\n",
    "    framework_version='2.1.0',\n",
    "    code_location=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "    output_path=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "    py_version='py3',\n",
    "    enable_sagemaker_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Pass the Trial object to the Estimator and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tensorflow-training-job-1586949168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-15 11:12:48 Starting - Starting the training job...\n",
      "2020-04-15 11:12:50 Starting - Launching requested ML instances......\n",
      "2020-04-15 11:14:15 Starting - Preparing the instances for training......\n",
      "2020-04-15 11:15:18 Downloading - Downloading input data...\n",
      "2020-04-15 11:15:30 Training - Downloading the training image...........\u001b[34m2020-04-15 11:17:27,441 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-04-15 11:17:27,911 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-job-1586949168\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"tensorflow_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"tensorflow_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=tensorflow_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=tensorflow_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-job-1586949168\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/source/sourcedir.tar.gz\",\"module_name\":\"tensorflow_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tensorflow_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 tensorflow_mnist.py --model_dir s3://sagemaker-workshop-420/mnist/tensorflow-training-job-1586949168/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-04-15 11:17:30.321 ip-10-0-116-5.us-east-2.compute.internal:20 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-04-15 11:17:30.322 ip-10-0-116-5.us-east-2.compute.internal:20 INFO hook.py:170] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-04-15 11:17:30.322 ip-10-0-116-5.us-east-2.compute.internal:20 INFO hook.py:215] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34mTrain on 55000 samples\u001b[0m\n",
      "\u001b[34m[2020-04-15 11:17:32.519 ip-10-0-116-5.us-east-2.compute.internal:20 INFO keras.py:69] Executing in TF2.x eager mode.TF 2.x eager doesn't provide gradient and optimizer variable values.SageMaker Debugger will not be saving gradients and optimizer variables in this case\u001b[0m\n",
      "\u001b[34m[2020-04-15 11:17:32.532 ip-10-0-116-5.us-east-2.compute.internal:20 INFO hook.py:351] Monitoring the collections: losses, metrics, sm_metrics\u001b[0m\n",
      "\u001b[34mERROR:root:'NoneType' object has no attribute 'write'\u001b[0m\n",
      "\n",
      "2020-04-15 11:17:44 Uploading - Uploading generated training model\u001b[34m#015   32/55000 [..............................] - ETA: 29:41 - loss: 2.4581 - accuracy: 0.0312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  512/55000 [..............................] - ETA: 1:56 - loss: 1.4924 - accuracy: 0.5332 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1024/55000 [..............................] - ETA: 1:00 - loss: 1.0901 - accuracy: 0.6631#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1568/55000 [..............................] - ETA: 40s - loss: 0.8877 - accuracy: 0.7251 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2112/55000 [>.............................] - ETA: 31s - loss: 0.7765 - accuracy: 0.7599#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2496/55000 [>.............................] - ETA: 27s - loss: 0.7227 - accuracy: 0.7796#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2784/55000 [>.............................] - ETA: 25s - loss: 0.6912 - accuracy: 0.7895#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3072/55000 [>.............................] - ETA: 23s - loss: 0.6605 - accuracy: 0.7965#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3488/55000 [>.............................] - ETA: 21s - loss: 0.6359 - accuracy: 0.8048#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4032/55000 [=>............................] - ETA: 18s - loss: 0.6044 - accuracy: 0.8147#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4608/55000 [=>............................] - ETA: 17s - loss: 0.5794 - accuracy: 0.8220#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5184/55000 [=>............................] - ETA: 15s - loss: 0.5503 - accuracy: 0.8301#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5760/55000 [==>...........................] - ETA: 14s - loss: 0.5261 - accuracy: 0.8366#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6304/55000 [==>...........................] - ETA: 13s - loss: 0.5128 - accuracy: 0.8417#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6880/55000 [==>...........................] - ETA: 12s - loss: 0.4962 - accuracy: 0.8478#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7424/55000 [===>..........................] - ETA: 11s - loss: 0.4853 - accuracy: 0.8514#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8000/55000 [===>..........................] - ETA: 10s - loss: 0.4695 - accuracy: 0.8574#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8544/55000 [===>..........................] - ETA: 10s - loss: 0.4584 - accuracy: 0.8611#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9120/55000 [===>..........................] - ETA: 9s - loss: 0.4483 - accuracy: 0.8646 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9664/55000 [====>.........................] - ETA: 9s - loss: 0.4399 - accuracy: 0.8670#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510208/55000 [====>.........................] - ETA: 9s - loss: 0.4318 - accuracy: 0.8694#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510752/55000 [====>.........................] - ETA: 8s - loss: 0.4251 - accuracy: 0.8717#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01511328/55000 [=====>........................] - ETA: 8s - loss: 0.4156 - accuracy: 0.8748#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01511872/55000 [=====>........................] - ETA: 8s - loss: 0.4087 - accuracy: 0.8769#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01512416/55000 [=====>........................] - ETA: 7s - loss: 0.4000 - accuracy: 0.8793#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01512960/55000 [======>.......................] - ETA: 7s - loss: 0.3957 - accuracy: 0.8807#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01513504/55000 [======>.......................] - ETA: 7s - loss: 0.3891 - accuracy: 0.8828#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01514016/55000 [======>.......................] - ETA: 7s - loss: 0.3863 - accuracy: 0.8841#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01514560/55000 [======>.......................] - ETA: 6s - loss: 0.3792 - accuracy: 0.8862#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01515072/55000 [=======>......................] - ETA: 6s - loss: 0.3736 - accuracy: 0.8876#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01515616/55000 [=======>......................] - ETA: 6s - loss: 0.3684 - accuracy: 0.8890#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516096/55000 [=======>......................] - ETA: 6s - loss: 0.3630 - accuracy: 0.8905#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516640/55000 [========>.....................] - ETA: 6s - loss: 0.3587 - accuracy: 0.8918#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517184/55000 [========>.....................] - ETA: 6s - loss: 0.3552 - accuracy: 0.8929#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517728/55000 [========>.....................] - ETA: 5s - loss: 0.3520 - accuracy: 0.8939#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518272/55000 [========>.....................] - ETA: 5s - loss: 0.3467 - accuracy: 0.8955#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518816/55000 [=========>....................] - ETA: 5s - loss: 0.3430 - accuracy: 0.8966#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01519392/55000 [=========>....................] - ETA: 5s - loss: 0.3387 - accuracy: 0.8978#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01519936/55000 [=========>....................] - ETA: 5s - loss: 0.3357 - accuracy: 0.8986#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520480/55000 [==========>...................] - ETA: 5s - loss: 0.3327 - accuracy: 0.8993#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01521024/55000 [==========>...................] - ETA: 4s - loss: 0.3303 - accuracy: 0.9000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01521600/55000 [==========>...................] - ETA: 4s - loss: 0.3271 - accuracy: 0.9013#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01522144/55000 [===========>..................] - ETA: 4s - loss: 0.3252 - accuracy: 0.9020#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01522688/55000 [===========>..................] - ETA: 4s - loss: 0.3227 - accuracy: 0.9027#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01523232/55000 [===========>..................] - ETA: 4s - loss: 0.3195 - accuracy: 0.9036#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01523808/55000 [===========>..................] - ETA: 4s - loss: 0.3160 - accuracy: 0.9045#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01524352/55000 [============>.................] - ETA: 4s - loss: 0.3140 - accuracy: 0.9052#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01524832/55000 [============>.................] - ETA: 4s - loss: 0.3113 - accuracy: 0.9061#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525408/55000 [============>.................] - ETA: 4s - loss: 0.3094 - accuracy: 0.9069#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525952/55000 [=============>................] - ETA: 3s - loss: 0.3073 - accuracy: 0.9076#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01526528/55000 [=============>................] - ETA: 3s - loss: 0.3039 - accuracy: 0.9085#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01527072/55000 [=============>................] - ETA: 3s - loss: 0.3011 - accuracy: 0.9094#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01527616/55000 [==============>...............] - ETA: 3s - loss: 0.2989 - accuracy: 0.9101#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01528160/55000 [==============>...............] - ETA: 3s - loss: 0.2968 - accuracy: 0.9106#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01528736/55000 [==============>...............] - ETA: 3s - loss: 0.2944 - accuracy: 0.9113#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01529312/55000 [==============>...............] - ETA: 3s - loss: 0.2933 - accuracy: 0.9116#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01529888/55000 [===============>..............] - ETA: 3s - loss: 0.2912 - accuracy: 0.9120#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01530432/55000 [===============>..............] - ETA: 3s - loss: 0.2884 - accuracy: 0.9129#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01530976/55000 [===============>..............] - ETA: 3s - loss: 0.2864 - accuracy: 0.9136#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01531552/55000 [================>.............] - ETA: 3s - loss: 0.2844 - accuracy: 0.9142#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01532064/55000 [================>.............] - ETA: 2s - loss: 0.2832 - accuracy: 0.9145#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01532576/55000 [================>.............] - ETA: 2s - loss: 0.2814 - accuracy: 0.9150#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01533120/55000 [=================>............] - ETA: 2s - loss: 0.2811 - accuracy: 0.9152#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01533664/55000 [=================>............] - ETA: 2s - loss: 0.2798 - accuracy: 0.9157#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01534208/55000 [=================>............] - ETA: 2s - loss: 0.2786 - accuracy: 0.9161#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01534752/55000 [=================>............] - ETA: 2s - loss: 0.2772 - accuracy: 0.9165#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01535296/55000 [==================>...........] - ETA: 2s - loss: 0.2758 - accuracy: 0.9169#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01535840/55000 [==================>...........] - ETA: 2s - loss: 0.2737 - accuracy: 0.9175#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01536416/55000 [==================>...........] - ETA: 2s - loss: 0.2717 - accuracy: 0.9184#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01536992/55000 [===================>..........] - ETA: 2s - loss: 0.2694 - accuracy: 0.9190#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01537536/55000 [===================>..........] - ETA: 2s - loss: 0.2675 - accuracy: 0.9196#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01538080/55000 [===================>..........] - ETA: 2s - loss: 0.2666 - accuracy: 0.9200#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01538656/55000 [====================>.........] - ETA: 1s - loss: 0.2653 - accuracy: 0.9205#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01539200/55000 [====================>.........] - ETA: 1s - loss: 0.2648 - accuracy: 0.9207#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01539776/55000 [====================>.........] - ETA: 1s - loss: 0.2629 - accuracy: 0.9213#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01540320/55000 [====================>.........] - ETA: 1s - loss: 0.2616 - accuracy: 0.9215#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01540896/55000 [=====================>........] - ETA: 1s - loss: 0.2597 - accuracy: 0.9221#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01541440/55000 [=====================>........] - ETA: 1s - loss: 0.2583 - accuracy: 0.9224#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01541952/55000 [=====================>........] - ETA: 1s - loss: 0.2575 - accuracy: 0.9226#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01542496/55000 [======================>.......] - ETA: 1s - loss: 0.2562 - accuracy: 0.9230#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01543040/55000 [======================>.......] - ETA: 1s - loss: 0.2545 - accuracy: 0.9234#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01543584/55000 [======================>.......] - ETA: 1s - loss: 0.2533 - accuracy: 0.9239#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01544128/55000 [=======================>......] - ETA: 1s - loss: 0.2524 - accuracy: 0.9242#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01544704/55000 [=======================>......] - ETA: 1s - loss: 0.2513 - accuracy: 0.9245#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01545280/55000 [=======================>......] - ETA: 1s - loss: 0.2501 - accuracy: 0.9249#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01545856/55000 [========================>.....] - ETA: 1s - loss: 0.2492 - accuracy: 0.9250#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01546368/55000 [========================>.....] - ETA: 1s - loss: 0.2479 - accuracy: 0.9254#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01546944/55000 [========================>.....] - ETA: 0s - loss: 0.2469 - accuracy: 0.9258#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01547520/55000 [========================>.....] - ETA: 0s - loss: 0.2460 - accuracy: 0.9260#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01548064/55000 [=========================>....] - ETA: 0s - loss: 0.2452 - accuracy: 0.9262#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01548608/55000 [=========================>....] - ETA: 0s - loss: 0.2440 - accuracy: 0.9266#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01549152/55000 [=========================>....] - ETA: 0s - loss: 0.2428 - accuracy: 0.9269#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01549696/55000 [==========================>...] - ETA: \u001b[0m\n",
      "\u001b[34m0s - loss: 0.2417 - accuracy: 0.9271#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01550240/55000 [==========================>...] - ETA: 0s - loss: 0.2409 - accuracy: 0.9273#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01550784/55000 [==========================>...] - ETA: 0s - loss: 0.2395 - accuracy: 0.9277#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01551328/55000 [==========================>...] - ETA: 0s - loss: 0.2384 - accuracy: 0.9280#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01551904/55000 [===========================>..] - ETA: 0s - loss: 0.2375 - accuracy: 0.9282#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01552448/55000 [===========================>..] - ETA: 0s - loss: 0.2369 - accuracy: 0.9284#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01553024/55000 [===========================>..] - ETA: 0s - loss: 0.2358 - accuracy: 0.9287#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01553600/55000 [============================>.] - ETA: 0s - loss: 0.2348 - accuracy: 0.9290#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01554176/55000 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.9292#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01554720/55000 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9292#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01555000/55000 [==============================] - 6s 114us/sample - loss: 0.2330 - accuracy: 0.9294\u001b[0m\n",
      "\u001b[34m#015   32/10000 [..............................] - ETA: 34s - loss: 0.0654 - accuracy: 0.9688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  512/10000 [>.............................] - ETA: 3s - loss: 0.1088 - accuracy: 0.9727 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1120/10000 [==>...........................] - ETA: 1s - loss: 0.1288 - accuracy: 0.9607#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1760/10000 [====>.........................] - ETA: 1s - loss: 0.1456 - accuracy: 0.9523#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2400/10000 [======>.......................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9483#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3040/10000 [========>.....................] - ETA: 0s - loss: 0.1483 - accuracy: 0.9520#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3680/10000 [==========>...................] - ETA: 0s - loss: 0.1469 - accuracy: 0.9535#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4352/10000 [============>.................] - ETA: 0s - loss: 0.1494 - accuracy: 0.9524#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4960/10000 [=============>................] - ETA: 0s - loss: 0.1473 - accuracy: 0.9530#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5632/10000 [===============>..............] - ETA: 0s - loss: 0.1373 - accuracy: 0.9561#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6304/10000 [=================>............] - ETA: 0s - loss: 0.1367 - accuracy: 0.9562#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6944/10000 [===================>..........] - ETA: 0s - loss: 0.1320 - accuracy: 0.9581#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7584/10000 [=====================>........] - ETA: 0s - loss: 0.1245 - accuracy: 0.9600#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8192/10000 [=======================>......] - ETA: 0s - loss: 0.1202 - accuracy: 0.9614#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8864/10000 [=========================>....] - ETA: 0s - loss: 0.1145 - accuracy: 0.9632#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9472/10000 [===========================>..] - ETA: 0s - loss: 0.1111 - accuracy: 0.9645#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510000/10000 [==============================] - 1s 93us/sample - loss: 0.1130 - accuracy: 0.9638\u001b[0m\n",
      "\u001b[34m2020-04-15 11:17:40.033879: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\u001b[0m\n",
      "\u001b[34m[2020-04-15 11:17:40.346 ip-10-0-116-5.us-east-2.compute.internal:20 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:17:40,935 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-15 11:17:51 Completed - Training job completed\n",
      "Training seconds: 153\n",
      "Billable seconds: 153\n"
     ]
    }
   ],
   "source": [
    "# Now associate the estimator with the Experiment and Trial\n",
    "tf_estimator.fit(\n",
    "    inputs={'training': training_data_uri}, \n",
    "    job_name=\"tensorflow-training-job-{}\".format(int(time.time())),\n",
    "    experiment_config={\n",
    "        \"TrialName\": trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"Training\",\n",
    "    },\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can view the `Experiment` metadata by clicking on the beaker icon in the vertical navigation bar on the left-side of your screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Search with PyTorch models\n",
    "\n",
    "We will use multiple `Trials` to perform hyperparameter search and find the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sagemaker.analytics import ExperimentAnalytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Dataset\n",
    "\n",
    "We download the MNIST hand written digits dataset, and then apply transformation on each of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325198fe18754048a00db453b955a4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d30287af30044f8bdfb62b63f333900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8489105ea04abcae74cee818652c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6becf635044c43fc91eee79d3b2bfeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Download, load, and transform the data.\n",
    "train_set = datasets.MNIST(LOCAL_DATA_DIRECTORY, train=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))]), \n",
    "    download=True)\n",
    "                           \n",
    "test_set = datasets.MNIST(LOCAL_DATA_DIRECTORY, train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_set.data[2].numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the images in the dataset, we upload it to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(\n",
    "    path=LOCAL_DATA_DIRECTORY,\n",
    "    bucket=BUCKET,\n",
    "    key_prefix=PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Use Experiment to track experiment metadata\n",
    "\n",
    "### Step 1. Track preprocessing steps.\n",
    "\n",
    "We'll first track the parameters from the data pre-processing step. These will then be passed to the hyperparameter jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sagemaker_client) as tracker:\n",
    "    tracker.log_parameters({\n",
    "        \"normalization_mean\": 0.1307,\n",
    "        \"normalization_std\": 0.3081,\n",
    "    })\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"mnist-dataset\", media_type=\"s3/uri\", value=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment = Experiment.create(\n",
    "    experiment_name=f\"torch-mnist-{int(time.time())}\", \n",
    "    description=\"Classification of mnist hand-written digits\", \n",
    "    sagemaker_boto_client=sagemaker_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f0779e00dd0>,experiment_name='torch-mnist-1586949677',description='Classification of mnist hand-written digits',experiment_arn='arn:aws:sagemaker:us-east-2:209970524256:experiment/torch-mnist-1586949677',response_metadata={'RequestId': '1c957d92-32c9-45de-9137-ffdf08cdb2de', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '1c957d92-32c9-45de-9137-ffdf08cdb2de', 'content-type': 'application/x-amz-json-1.1', 'content-length': '94', 'date': 'Wed, 15 Apr 2020 11:21:17 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "print(mnist_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Track Experiment\n",
    "\n",
    "While training the CNN model on SageMaker, we will experiment with several values for the number of hidden channel in the model. We will create a Trial to track each training job run. We will also create a TrialComponent from the tracker we created before, and add to the Trial. This will enrich the Trial with the parameters we captured from the data pre-processing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-pytorch-2020-04-15-11-21-30-634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-15 11:21:30 Starting - Starting the training job...\n",
      "2020-04-15 11:21:33 Starting - Launching requested ML instances......\n",
      "2020-04-15 11:22:33 Starting - Preparing the instances for training...\n",
      "2020-04-15 11:23:15 Downloading - Downloading input data...\n",
      "2020-04-15 11:23:59 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:00,316 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:00,318 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:00,330 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:03,344 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:03,596 sagemaker-containers INFO     Module pytorch_mnist does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:03,605 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:03,605 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:03,605 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pytorch-mnist\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: started\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-41hjcwig/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built pytorch-mnist\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytorch-mnist\u001b[0m\n",
      "\u001b[34mSuccessfully installed pytorch-mnist-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:05,384 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:05,396 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"optimizer\": \"sgd\",\n",
      "        \"hidden_channels\": 2,\n",
      "        \"dropout\": 0.2,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-04-15-11-21-30-634\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-21-30-634/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pytorch_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pytorch_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":2,\"optimizer\":\"sgd\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pytorch_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pytorch_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-21-30-634/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":2,\"optimizer\":\"sgd\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-04-15-11-21-30-634\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-21-30-634/source/sourcedir.tar.gz\",\"module_name\":\"pytorch_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pytorch_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--dropout\",\"0.2\",\"--epochs\",\"2\",\"--hidden_channels\",\"2\",\"--optimizer\",\"sgd\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=sgd\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_CHANNELS=2\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pytorch_mnist --backend gloo --dropout 0.2 --epochs 2 --hidden_channels 2 --optimizer sgd\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 60000/60000 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/60000 (11%)], Train Loss: 1.617049;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)], Train Loss: 0.941270;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/60000 (32%)], Train Loss: 0.843992;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)], Train Loss: 0.432059;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)], Train Loss: 0.464780;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)], Train Loss: 0.322854;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/60000 (75%)], Train Loss: 0.351526;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)], Train Loss: 0.389307;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [57600/60000 (96%)], Train Loss: 0.375780;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1852, Test Accuracy: 95%;\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/60000 (11%)], Train Loss: 0.275706;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)], Train Loss: 0.292543;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/60000 (32%)], Train Loss: 0.244455;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)], Train Loss: 0.283167;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/60000 (53%)], Train Loss: 0.279576;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)], Train Loss: 0.341436;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/60000 (75%)], Train Loss: 0.414407;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)], Train Loss: 0.193495;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [57600/60000 (96%)], Train Loss: 0.157259;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1158, Test Accuracy: 97%;\n",
      "\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:24:46,898 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-15 11:24:57 Uploading - Uploading generated training model\n",
      "2020-04-15 11:24:57 Completed - Training job completed\n",
      "Training seconds: 102\n",
      "Billable seconds: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-pytorch-2020-04-15-11-25-15-923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-15 11:25:16 Starting - Starting the training job...\n",
      "2020-04-15 11:25:17 Starting - Launching requested ML instances...\n",
      "2020-04-15 11:26:13 Starting - Preparing the instances for training......\n",
      "2020-04-15 11:26:55 Downloading - Downloading input data...\n",
      "2020-04-15 11:27:35 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:36,455 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:36,458 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:36,469 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:39,486 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:39,739 sagemaker-containers INFO     Module pytorch_mnist does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:39,739 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:39,739 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:39,739 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pytorch-mnist\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: started\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ty6ayvv5/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built pytorch-mnist\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytorch-mnist\u001b[0m\n",
      "\u001b[34mSuccessfully installed pytorch-mnist-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:41,366 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-15 11:27:41,379 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"optimizer\": \"sgd\",\n",
      "        \"hidden_channels\": 5,\n",
      "        \"dropout\": 0.2,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-04-15-11-25-15-923\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-25-15-923/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pytorch_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pytorch_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":5,\"optimizer\":\"sgd\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pytorch_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pytorch_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-25-15-923/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":5,\"optimizer\":\"sgd\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-04-15-11-25-15-923\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-25-15-923/source/sourcedir.tar.gz\",\"module_name\":\"pytorch_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pytorch_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--dropout\",\"0.2\",\"--epochs\",\"2\",\"--hidden_channels\",\"5\",\"--optimizer\",\"sgd\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=sgd\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_CHANNELS=5\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pytorch_mnist --backend gloo --dropout 0.2 --epochs 2 --hidden_channels 5 --optimizer sgd\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 60000/60000 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/60000 (11%)], Train Loss: 1.698200;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)], Train Loss: 0.994831;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/60000 (32%)], Train Loss: 0.611539;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)], Train Loss: 0.648925;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)], Train Loss: 0.571486;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)], Train Loss: 0.791933;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/60000 (75%)], Train Loss: 0.438099;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)], Train Loss: 0.549112;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [57600/60000 (96%)], Train Loss: 0.480673;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1914, Test Accuracy: 94%;\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/60000 (11%)], Train Loss: 0.297167;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)], Train Loss: 0.364907;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/60000 (32%)], Train Loss: 0.268553;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)], Train Loss: 0.272427;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/60000 (53%)], Train Loss: 0.382764;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)], Train Loss: 0.482188;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/60000 (75%)], Train Loss: 0.203590;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)], Train Loss: 0.445356;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [57600/60000 (96%)], Train Loss: 0.197844;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1157, Test Accuracy: 96%;\n",
      "\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:28:22,790 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-15 11:28:34 Uploading - Uploading generated training model\n",
      "2020-04-15 11:28:34 Completed - Training job completed\n",
      "Training seconds: 99\n",
      "Billable seconds: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-pytorch-2020-04-15-11-29-00-623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-15 11:29:00 Starting - Starting the training job...\n",
      "2020-04-15 11:29:04 Starting - Launching requested ML instances...\n",
      "2020-04-15 11:29:59 Starting - Preparing the instances for training......\n",
      "2020-04-15 11:30:37 Downloading - Downloading input data...\n",
      "2020-04-15 11:31:21 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:22,841 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:22,843 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:22,855 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:22,856 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:23,103 sagemaker-containers INFO     Module pytorch_mnist does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:23,103 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:23,103 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:23,104 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pytorch-mnist\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: started\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kw833sdi/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built pytorch-mnist\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytorch-mnist\u001b[0m\n",
      "\u001b[34mSuccessfully installed pytorch-mnist-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:24,887 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-15 11:31:24,900 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"optimizer\": \"sgd\",\n",
      "        \"hidden_channels\": 10,\n",
      "        \"dropout\": 0.2,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-04-15-11-29-00-623\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-29-00-623/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pytorch_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pytorch_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":10,\"optimizer\":\"sgd\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pytorch_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pytorch_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-29-00-623/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":10,\"optimizer\":\"sgd\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-04-15-11-29-00-623\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-workshop-420/mnist/sagemaker-pytorch-2020-04-15-11-29-00-623/source/sourcedir.tar.gz\",\"module_name\":\"pytorch_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pytorch_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--dropout\",\"0.2\",\"--epochs\",\"2\",\"--hidden_channels\",\"10\",\"--optimizer\",\"sgd\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=sgd\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_CHANNELS=10\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pytorch_mnist --backend gloo --dropout 0.2 --epochs 2 --hidden_channels 10 --optimizer sgd\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 60000/60000 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/60000 (11%)], Train Loss: 1.695285;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)], Train Loss: 0.928432;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/60000 (32%)], Train Loss: 0.702160;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)], Train Loss: 0.442871;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)], Train Loss: 0.413667;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)], Train Loss: 0.501132;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/60000 (75%)], Train Loss: 0.383585;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)], Train Loss: 0.328490;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [57600/60000 (96%)], Train Loss: 0.396089;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1679, Test Accuracy: 95%;\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/60000 (11%)], Train Loss: 0.603119;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)], Train Loss: 0.229334;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/60000 (32%)], Train Loss: 0.281790;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)], Train Loss: 0.376957;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/60000 (53%)], Train Loss: 0.412861;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)], Train Loss: 0.200810;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/60000 (75%)], Train Loss: 0.233049;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)], Train Loss: 0.319483;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [57600/60000 (96%)], Train Loss: 0.210030;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1060, Test Accuracy: 97%;\n",
      "\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2020-04-15 11:32:14,962 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-15 11:32:25 Uploading - Uploading generated training model\n",
      "2020-04-15 11:32:25 Completed - Training job completed\n",
      "Training seconds: 108\n",
      "Billable seconds: 108\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Keep references to each Trial object\n",
    "hidden_channel_trial_name_map = {}\n",
    "preprocessing_trial_component = tracker.trial_component\n",
    "\n",
    "# If you want to run the following training jobs asynchronously, you may need to increase\n",
    "# your resource limit. Otherwise, you can run them sequentially.\n",
    "for i, num_hidden_channel in enumerate([2, 5, 10]):\n",
    "    \n",
    "    # create Trial oobject\n",
    "    trial_name = f\"torch-{num_hidden_channel}-hidden-channels-{int(time.time())}\"\n",
    "    cnn_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "        experiment_name=mnist_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sagemaker_client,\n",
    "    )\n",
    "    hidden_channel_trial_name_map[num_hidden_channel] = trial_name\n",
    "    \n",
    "    # Associate the proprocessing trial component with the current trial\n",
    "    cnn_trial.add_trial_component(preprocessing_trial_component)\n",
    "    \n",
    "    # all input configurations, parameters, and metrics specified in estimator \n",
    "    # definition are automatically tracked\n",
    "    estimator = PyTorch(\n",
    "        entry_point='../scripts/pytorch_mnist.py',\n",
    "        role=role,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        framework_version='1.1.0',\n",
    "        train_instance_count=1,\n",
    "        train_instance_type='ml.c4.xlarge',\n",
    "        code_location=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "        output_path=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "        hyperparameters={\n",
    "            'epochs': 2,\n",
    "            'backend': 'gloo',\n",
    "            'hidden_channels': num_hidden_channel,\n",
    "            'dropout': 0.2,\n",
    "            'optimizer': 'sgd'\n",
    "        },\n",
    "        metric_definitions=[\n",
    "            {'Name':'train:loss', 'Regex':'Train Loss: (.*?);'},\n",
    "            {'Name':'test:loss', 'Regex':'Test Average loss: (.*?),'},\n",
    "            {'Name':'test:accuracy', 'Regex':'Test Accuracy: (.*?)%;'}\n",
    "        ],\n",
    "        enable_sagemaker_metrics=True,\n",
    "    )\n",
    "    \n",
    "    # Now associate the estimator with the Experiment and Trial\n",
    "    estimator.fit(\n",
    "        inputs={'training': inputs}, \n",
    "        experiment_config={\n",
    "            \"TrialName\": cnn_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "        wait=True,\n",
    "    )\n",
    "    \n",
    "    # give it a while before dispatching the next training job\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Compare the model training runs for an experiment\n",
    "\n",
    "Now we will use the analytics capabilities of Python SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\":[\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    experiment_name=mnist_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.test:accuracy.max\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=['test:accuracy'],\n",
    "    parameter_names=['hidden_channels', 'epochs', 'dropout', 'optimizer']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>test:accuracy - Min</th>\n",
       "      <th>test:accuracy - Max</th>\n",
       "      <th>test:accuracy - Avg</th>\n",
       "      <th>test:accuracy - StdDev</th>\n",
       "      <th>test:accuracy - Last</th>\n",
       "      <th>test:accuracy - Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sagemaker-pytorch-2020-04-15-11-21-30-634-aws-...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:209970524256:train...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"sgd\"</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sagemaker-pytorch-2020-04-15-11-29-00-623-aws-...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:209970524256:train...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"sgd\"</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sagemaker-pytorch-2020-04-15-11-25-15-923-aws-...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:209970524256:train...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>\"sgd\"</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName DisplayName  \\\n",
       "0  sagemaker-pytorch-2020-04-15-11-21-30-634-aws-...    Training   \n",
       "1  sagemaker-pytorch-2020-04-15-11-29-00-623-aws-...    Training   \n",
       "2  sagemaker-pytorch-2020-04-15-11-25-15-923-aws-...    Training   \n",
       "\n",
       "                                           SourceArn  dropout  epochs  \\\n",
       "0  arn:aws:sagemaker:us-east-2:209970524256:train...      0.2     2.0   \n",
       "1  arn:aws:sagemaker:us-east-2:209970524256:train...      0.2     2.0   \n",
       "2  arn:aws:sagemaker:us-east-2:209970524256:train...      0.2     2.0   \n",
       "\n",
       "   hidden_channels optimizer  test:accuracy - Min  test:accuracy - Max  \\\n",
       "0              2.0     \"sgd\"                 95.0                 97.0   \n",
       "1             10.0     \"sgd\"                 95.0                 97.0   \n",
       "2              5.0     \"sgd\"                 94.0                 96.0   \n",
       "\n",
       "   test:accuracy - Avg  test:accuracy - StdDev  test:accuracy - Last  \\\n",
       "0                 96.0                1.414214                  97.0   \n",
       "1                 96.0                1.414214                  97.0   \n",
       "2                 95.0                1.414214                  96.0   \n",
       "\n",
       "   test:accuracy - Count  \n",
       "0                      2  \n",
       "1                      2  \n",
       "2                      2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To isolate and measure the impact of change in hidden channels on model accuracy, we vary the number of hidden channel and fix the value for other hyperparameters.\n",
    "\n",
    "Next let's look at an example of tracing the lineage of a model by accessing the data tracked by SageMaker Experiments for `cnn-training-job-2-hidden-channels` trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    search_expression={\n",
    "        \"Filters\":[{\n",
    "            \"Name\": \"Parents.TrialName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": hidden_channel_trial_name_map[2]\n",
    "        }]\n",
    "    },\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>normalization_mean</th>\n",
       "      <th>normalization_std</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>backend</th>\n",
       "      <th>...</th>\n",
       "      <th>test:accuracy - Avg</th>\n",
       "      <th>test:accuracy - StdDev</th>\n",
       "      <th>test:accuracy - Last</th>\n",
       "      <th>test:accuracy - Count</th>\n",
       "      <th>train:loss - Min</th>\n",
       "      <th>train:loss - Max</th>\n",
       "      <th>train:loss - Avg</th>\n",
       "      <th>train:loss - StdDev</th>\n",
       "      <th>train:loss - Last</th>\n",
       "      <th>train:loss - Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrialComponent-2020-04-15-112114-awyd</td>\n",
       "      <td>Preprocessing</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.3081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sagemaker-pytorch-2020-04-15-11-21-30-634-aws-...</td>\n",
       "      <td>Training</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:209970524256:train...</td>\n",
       "      <td>520713654638.dkr.ecr.us-east-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c4.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"gloo\"</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.157259</td>\n",
       "      <td>1.617049</td>\n",
       "      <td>0.456703</td>\n",
       "      <td>0.352488</td>\n",
       "      <td>0.157259</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName    DisplayName  \\\n",
       "0              TrialComponent-2020-04-15-112114-awyd  Preprocessing   \n",
       "1  sagemaker-pytorch-2020-04-15-11-21-30-634-aws-...       Training   \n",
       "\n",
       "   normalization_mean  normalization_std  \\\n",
       "0              0.1307             0.3081   \n",
       "1                 NaN                NaN   \n",
       "\n",
       "                                           SourceArn  \\\n",
       "0                                                NaN   \n",
       "1  arn:aws:sagemaker:us-east-2:209970524256:train...   \n",
       "\n",
       "                                  SageMaker.ImageUri  SageMaker.InstanceCount  \\\n",
       "0                                                NaN                      NaN   \n",
       "1  520713654638.dkr.ecr.us-east-2.amazonaws.com/s...                      1.0   \n",
       "\n",
       "  SageMaker.InstanceType  SageMaker.VolumeSizeInGB backend  ...  \\\n",
       "0                    NaN                       NaN     NaN  ...   \n",
       "1           ml.c4.xlarge                      30.0  \"gloo\"  ...   \n",
       "\n",
       "   test:accuracy - Avg  test:accuracy - StdDev  test:accuracy - Last  \\\n",
       "0                  NaN                     NaN                   NaN   \n",
       "1                 96.0                1.414214                  97.0   \n",
       "\n",
       "  test:accuracy - Count  train:loss - Min train:loss - Max train:loss - Avg  \\\n",
       "0                   NaN               NaN              NaN              NaN   \n",
       "1                   2.0          0.157259         1.617049         0.456703   \n",
       "\n",
       "  train:loss - StdDev train:loss - Last train:loss - Count  \n",
       "0                 NaN               NaN                NaN  \n",
       "1            0.352488          0.157259               18.0  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineage_table.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:environment/datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
