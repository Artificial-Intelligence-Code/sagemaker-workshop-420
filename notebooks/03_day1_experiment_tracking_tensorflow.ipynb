{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use Experiments, Trials, and Search to Organize ML Experiments.\n",
    "\n",
    "* Goals\n",
    "    * Train Tensorflow and PyTorch models\n",
    "    * Organize training using `Experiments` and `Trials`\n",
    "    * Use SageMaker Search functionality to find the best model.\n",
    "* Code adapted from [tensorflow_script_mode_training_and_serving](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_script_mode_training_and_serving/tensorflow_script_mode_training_and_serving.ipynb) and [pytorch_mnist](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/pytorch_mnist/pytorch_mnist.ipynb) notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/sagemaker-workshop-420/day_1\n"
     ]
    }
   ],
   "source": [
    "%cd /root/sagemaker-workshop-420/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts will be written to s3://sagemaker-workshop-420/mnist\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'sagemaker-workshop-420'\n",
    "PREFIX = 'mnist'\n",
    "\n",
    "LOCAL_DATA_DIRECTORY = f'../data/{PREFIX}'\n",
    "\n",
    "print(f\"Artifacts will be written to s3://{BUCKET}/{PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets create our Sagemaker session and role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::209970524256:role/service-role/AmazonSageMaker-ExecutionRole-20200402T065938\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "sagemaker_client = boto_session.client('sagemaker')\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session,\n",
    "                                      sagemaker_client=sagemaker_client)\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing a Tensorflow Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create an Experiment\n",
    "\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : \n",
    "\n",
    "1. a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or \n",
    "2. a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”),\n",
    "3. a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment = Experiment.create(\n",
    "    experiment_name=f\"tf-mnist-classification-{int(time.time())}\", \n",
    "    description=\"Classification of mnist hand-written digits using tensorflow\", \n",
    "    sagemaker_boto_client=sagemaker_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f8f80d717d0>,experiment_name='tf-mnist-classification-1586639823',description='Classification of mnist hand-written digits using tensorflow',experiment_arn='arn:aws:sagemaker:us-east-2:209970524256:experiment/tf-mnist-classification-1586639823',response_metadata={'RequestId': '2d26218b-41be-48c5-8f7d-76c395f509f1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2d26218b-41be-48c5-8f7d-76c395f509f1', 'content-type': 'application/x-amz-json-1.1', 'content-length': '106', 'date': 'Sat, 11 Apr 2020 21:17:03 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "print(mnist_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment using Trials\n",
    "\n",
    "Now create a Trial for each training run to track the it's inputs, parameters, and metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Tensorflow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data\n",
    "\n",
    "The MNIST dataset has been loaded to the public S3 buckets ``sagemaker-sample-data-<REGION>`` under the prefix ``tensorflow/mnist``. There are four ``.npy`` file under this prefix:\n",
    "* ``train_data.npy``\n",
    "* ``eval_data.npy``\n",
    "* ``train_labels.npy``\n",
    "* ``eval_labels.npy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-sample-data-us-east-2/tensorflow/mnist'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_uri = f's3://sagemaker-sample-data-{region}/tensorflow/mnist'\n",
    "training_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial's training script was adapted from TensorFlow's official [CNN MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py). We have modified it to handle the ``model_dir`` parameter passed in by SageMaker. This is an S3 path which can be used for data sharing during distributed training and checkpointing and/or model persistence. We have also added an argument-parsing function to handle processing training-related variables.\n",
    "\n",
    "At the end of the training job we have added a step to export the trained model to the path stored in the environment variable ``SM_MODEL_DIR``, which always points to ``/opt/ml/model``. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training.\n",
    "\n",
    "Here is the entire script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\n",
      "\u001b[37m# language governing permissions and limitations under the License.import tensorflow as tf\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel\u001b[39;49;00m(x_train, y_train, x_test, y_test):\n",
      "    \u001b[33m\"\"\"Generate a simple model\"\"\"\u001b[39;49;00m\n",
      "    model = tf.keras.models.Sequential([\n",
      "        tf.keras.layers.Flatten(),\n",
      "        tf.keras.layers.Dense(\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu),\n",
      "        tf.keras.layers.Dropout(\u001b[34m0.4\u001b[39;49;00m),\n",
      "        tf.keras.layers.Dense(\u001b[34m10\u001b[39;49;00m, activation=tf.nn.softmax)\n",
      "    ])\n",
      "\n",
      "    model.compile(optimizer=\u001b[33m'\u001b[39;49;00m\u001b[33madam\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  loss=\u001b[33m'\u001b[39;49;00m\u001b[33msparse_categorical_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    model.fit(x_train, y_train)\n",
      "    model.evaluate(x_test, y_test)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\n",
      "    \u001b[33m\"\"\"Load MNIST training data\"\"\"\u001b[39;49;00m\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\n",
      "    \u001b[33m\"\"\"Load MNIST testing data\"\"\"\u001b[39;49;00m\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    args, unknown = _parse_args()\n",
      "\n",
      "    train_data, train_labels = _load_training_data(args.train)\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\n",
      "\n",
      "    mnist_classifier = model(train_data, train_labels, eval_data, eval_labels)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\n",
      "        \u001b[37m# save model to an S3 directory with version number '00000001'\u001b[39;49;00m\n",
      "        mnist_classifier.save(os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33m000000001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mmy_model.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow 2.1 script\n",
    "!pygmentize '../scripts/tensorflow_mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create an Experiment\n",
    "\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work. You can create experiments to organize all your model development work for : \n",
    "\n",
    "1. a business use case you are addressing (e.g. create experiment named “customer churn prediction”), or \n",
    "2. a data science team that owns the experiment (e.g. create experiment named “marketing analytics experiment”),\n",
    "3. a specific data science and ML project. Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment = Experiment.create(\n",
    "    experiment_name=f\"tf-mnist-classification-{int(time.time())}\", \n",
    "    description=\"Classification of mnist hand-written digits using tensorflow\", \n",
    "    sagemaker_boto_client=sagemaker_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f8f80d717d0>,experiment_name='tf-mnist-classification-1586639823',description='Classification of mnist hand-written digits using tensorflow',experiment_arn='arn:aws:sagemaker:us-east-2:209970524256:experiment/tf-mnist-classification-1586639823',response_metadata={'RequestId': '2d26218b-41be-48c5-8f7d-76c395f509f1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2d26218b-41be-48c5-8f7d-76c395f509f1', 'content-type': 'application/x-amz-json-1.1', 'content-length': '106', 'date': 'Sat, 11 Apr 2020 21:17:03 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "print(mnist_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment using Trials\n",
    "\n",
    "Now create a Trial for each training run to track the it's inputs, parameters, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = f\"tensorflow-mnist-{int(time.time())}\"\n",
    "\n",
    "trial = Trial.create(\n",
    "    trial_name=trial_name, \n",
    "    experiment_name=mnist_experiment.experiment_name,\n",
    "    sagemaker_boto_client=sagemaker_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sagemaker.tensorflow.TensorFlow` estimator handles locating the script mode container, uploading your script to a S3 location and creating a SageMaker training job. Let's call out a couple important parameters here:\n",
    "\n",
    "* `py_version` is set to `'py3'` to indicate that we are using script mode since legacy mode supports only Python 2. Though Python 2 will be deprecated soon, you can use script mode with Python 2 by setting `py_version` to `'py2'` and `script_mode` to `True`.\n",
    "* `enable_sagemaker_metrics` is set to `True` to capture metrics like `accuracy` and `loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tensorflow-training-job-1586640199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 21:23:20 Starting - Starting the training job...\n",
      "2020-04-11 21:23:21 Starting - Launching requested ML instances...\n",
      "2020-04-11 21:24:18 Starting - Preparing the instances for training.........\n",
      "2020-04-11 21:25:49 Downloading - Downloading input data\n",
      "2020-04-11 21:25:49 Training - Downloading the training image.........\n",
      "2020-04-11 21:27:10 Training - Training image download completed. Training in progress.\u001b[34m2020-04-11 21:27:14,596 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-04-11 21:27:15,043 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-job-1586640199\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"tensorflow_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"tensorflow_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=tensorflow_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=tensorflow_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-job-1586640199\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/source/sourcedir.tar.gz\",\"module_name\":\"tensorflow_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tensorflow_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 tensorflow_mnist.py --model_dir s3://sagemaker-us-east-2-209970524256/tensorflow-training-job-1586640199/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-04-11 21:27:17.365 ip-10-0-138-115.us-east-2.compute.internal:21 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-04-11 21:27:17.365 ip-10-0-138-115.us-east-2.compute.internal:21 INFO hook.py:170] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-04-11 21:27:17.365 ip-10-0-138-115.us-east-2.compute.internal:21 INFO hook.py:215] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34mTrain on 55000 samples\u001b[0m\n",
      "\u001b[34m[2020-04-11 21:27:19.614 ip-10-0-138-115.us-east-2.compute.internal:21 INFO keras.py:69] Executing in TF2.x eager mode.TF 2.x eager doesn't provide gradient and optimizer variable values.SageMaker Debugger will not be saving gradients and optimizer variables in this case\u001b[0m\n",
      "\u001b[34m[2020-04-11 21:27:19.628 ip-10-0-138-115.us-east-2.compute.internal:21 INFO hook.py:351] Monitoring the collections: sm_metrics, metrics, losses\u001b[0m\n",
      "\u001b[34mERROR:root:'NoneType' object has no attribute 'write'\u001b[0m\n",
      "\u001b[34m#015   32/55000 [..............................] - ETA: 31:55 - loss: 2.4721 - accuracy: 0.0625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  192/55000 [..............................] - ETA: 5:33 - loss: 2.0603 - accuracy: 0.3073 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  512/55000 [..............................] - ETA: 2:10 - loss: 1.4854 - accuracy: 0.5664#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  992/55000 [..............................] - ETA: 1:09 - loss: 1.0751 - accuracy: 0.6835#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1536/55000 [..............................] - ETA: 46s - loss: 0.8753 - accuracy: 0.7383 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2048/55000 [>.............................] - ETA: 35s - loss: 0.7793 - accuracy: 0.7666#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2592/55000 [>.............................] - ETA: 28s - loss: 0.7003 - accuracy: 0.7897#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3168/55000 [>.............................] - ETA: 24s - loss: 0.6443 - accuracy: 0.8052#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3744/55000 [=>............................] - ETA: 21s - loss: 0.5993 - accuracy: 0.8197#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4320/55000 [=>............................] - ETA: 18s - loss: 0.5664 - accuracy: 0.8301#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4864/55000 [=>............................] - ETA: 16s - loss: 0.5498 - accuracy: 0.8359#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5440/55000 [=>............................] - ETA: 15s - loss: 0.5309 - accuracy: 0.8408#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6016/55000 [==>...........................] - ETA: 14s - loss: 0.5116 - accuracy: 0.8469#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6592/55000 [==>...........................] - ETA: 13s - loss: 0.4951 - accuracy: 0.8522#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7168/55000 [==>...........................] - ETA: 12s - loss: 0.4836 - accuracy: 0.8564#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7744/55000 [===>..........................] - ETA: 11s - loss: 0.4716 - accuracy: 0.8592#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8320/55000 [===>..........................] - ETA: 10s - loss: 0.4591 - accuracy: 0.8631#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8896/55000 [===>..........................] - ETA: 10s - loss: 0.4513 - accuracy: 0.8652#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9472/55000 [====>.........................] - ETA: 9s - loss: 0.4433 - accuracy: 0.8680 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510048/55000 [====>.........................] - ETA: 9s - loss: 0.4332 - accuracy: 0.8713#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510592/55000 [====>.........................] - ETA: 9s - loss: 0.4254 - accuracy: 0.8727#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01511136/55000 [=====>........................] - ETA: 8s - loss: 0.4192 - accuracy: 0.8746#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01511680/55000 [=====>........................] - ETA: 8s - loss: 0.4116 - accuracy: 0.8769#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01512256/55000 [=====>........................] - ETA: 8s - loss: 0.4040 - accuracy: 0.8792#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01512768/55000 [=====>........................] - ETA: 7s - loss: 0.3989 - accuracy: 0.8808#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01513344/55000 [======>.......................] - ETA: 7s - loss: 0.3933 - accuracy: 0.8828#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01513920/55000 [======>.......................] - ETA: 7s - loss: 0.3876 - accuracy: 0.8846#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01514496/55000 [======>.......................] - ETA: 7s - loss: 0.3835 - accuracy: 0.8858#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01515072/55000 [=======>......................] - ETA: 6s - loss: 0.3773 - accuracy: 0.8874#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01515616/55000 [=======>......................] - ETA: 6s - loss: 0.3713 - accuracy: 0.8891#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516128/55000 [=======>......................] - ETA: 6s - loss: 0.3666 - accuracy: 0.8905#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516704/55000 [========>.....................] - ETA: 6s - loss: 0.3615 - accuracy: 0.8916#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517280/55000 [========>.....................] - ETA: 6s - loss: 0.3557 - accuracy: 0.8935#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01517856/55000 [========>.....................] - ETA: 5s - loss: 0.3508 - accuracy: 0.8945#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01518432/55000 [=========>....................] - ETA: 5s - loss: 0.3467 - accuracy: 0.8959#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01519008/55000 [=========>....................] - ETA: 5s - loss: 0.3435 - accuracy: 0.8967#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01519584/55000 [=========>....................] - ETA: 5s - loss: 0.3404 - accuracy: 0.8976#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520160/55000 [=========>....................] - ETA: 5s - loss: 0.3370 - accuracy: 0.8987#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520736/55000 [==========>...................] - ETA: 5s - loss: 0.3330 - accuracy: 0.8997#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01521312/55000 [==========>...................] - ETA: 4s - loss: 0.3290 - accuracy: 0.9010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01521888/55000 [==========>...................] - ETA: 4s - loss: 0.3266 - accuracy: 0.9018#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01522464/55000 [===========>..................] - ETA: 4s - loss: 0.3229 - accuracy: 0.9030#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01523040/55000 [===========>..................] - ETA: 4s - loss: 0.3197 - accuracy: 0.9037#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01523584/55000 [===========>..................] - ETA: 4s - loss: 0.3164 - accuracy: 0.9049#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01524128/55000 [============>.................] - ETA: 4s - loss: 0.3144 - accuracy: 0.9056#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01524704/55000 [============>.................] - ETA: 4s - loss: 0.3111 - accuracy: 0.9067#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525280/55000 [============>.................] - ETA: 4s - loss: 0.3071 - accuracy: 0.9076#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01525856/55000 [=============>................] - ETA: 3s - loss: 0.3043 - accuracy: 0.9085#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01526432/55000 [=============>................] - ETA: 3s - loss: 0.3031 - accuracy: 0.9090#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01527008/55000 [=============>................] - ETA: 3s - loss: 0.3008 - accuracy: 0.9097#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01527584/55000 [==============>...............] - ETA: 3s - loss: 0.2985 - accuracy: 0.9101#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01528160/55000 [==============>...............] - ETA: 3s - loss: 0.2958 - accuracy: 0.9109#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01528736/55000 [==============>...............] - ETA: 3s - loss: 0.2936 - accuracy: 0.9115#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01529312/55000 [==============>...............] - ETA: 3s - loss: 0.2915 - accuracy: 0.9120#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01529888/55000 [===============>..............] - ETA: 3s - loss: 0.2895 - accuracy: 0.9126#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01530464/55000 [===============>..............] - ETA: 3s - loss: 0.2865 - accuracy: 0.9136#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01531040/55000 [===============>..............] - ETA: 3s - loss: 0.2854 - accuracy: 0.9139#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01531616/55000 [================>.............] - ETA: 2s - loss: 0.2842 - accuracy: 0.9141#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01532160/55000 [================>.............] - ETA: 2s - loss: 0.2828 - accuracy: 0.9145#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01532736/55000 [================>.............] - ETA: 2s - loss: 0.2813 - accuracy: 0.9149#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01533312/55000 [=================>............] - ETA: 2s - loss: 0.2797 - accuracy: 0.9156#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01533888/55000 [=================>............] - ETA: 2s - loss: 0.2785 - accuracy: 0.9161#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01534464/55000 [=================>............] - ETA: 2s - loss: 0.2761 - accuracy: 0.9168#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01535008/55000 [==================>...........] - ETA: 2s - loss: 0.2749 - accuracy: 0.9171#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01535584/55000 [==================>...........] - ETA: 2s - loss: 0.2727 - accuracy: 0.9179#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01536160/55000 [==================>...........] - ETA: 2s - loss: 0.2712 - accuracy: 0.9183#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01536736/55000 [===================>..........] - ETA: 2s - loss: 0.2690 - accuracy: 0.9188#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01537312/55000 [===================>..........] - ETA: 2s - loss: 0.2678 - accuracy: 0.9191#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01537888/55000 [===================>..........] - ETA: 2s - loss: 0.2661 - accuracy: 0.9197#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01538464/55000 [===================>..........] - ETA: 1s - loss: 0.2647 - accuracy: 0.9202#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01539040/55000 [====================>.........] - ETA: 1s - loss: 0.2625 - accuracy: 0.9209#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01539616/55000 [====================>.........] - ETA: 1s - loss: 0.2614 - accuracy: 0.9211#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01540192/55000 [====================>.........] - ETA: 1s - loss: 0.2602 - accuracy: 0.9214#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01540768/55000 [=====================>........] - ETA: 1s - loss: 0.2591 - accuracy: 0.9218#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01541344/55000 [=====================>........] - ETA: 1s - loss: 0.2585 - accuracy: 0.9220#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01541920/55000 [=====================>........] - ETA: 1s - loss: 0.2575 - accuracy: 0.9224#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01542496/55000 [======================>.......] - ETA: 1s - loss: 0.2563 - accuracy: 0.9229#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01543072/55000 [======================>.......] - ETA: 1s - loss: 0.2553 - accuracy: 0.9232#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01543648/55000 [======================>.......] - ETA: 1s - loss: 0.2541 - accuracy: 0.9235#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01544224/55000 [=======================>......] - ETA: 1s - loss: 0.2530 - accuracy: 0.9238#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01544800/55000 [=======================>......] - ETA: 1s - loss: 0.2519 - accuracy: 0.9241#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01545376/55000 [=======================>......] - ETA: 1s - loss: 0.2507 - accuracy: 0.9245#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01545952/55000 [========================>.....] - ETA: 1s - loss: 0.2490 - accuracy: 0.9251#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01546464/55000 [========================>.....] - ETA: 0s - loss: 0.2478 - accuracy: 0.9254#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01547040/55000 [========================>.....] - ETA: 0s - loss: 0.2466 - accuracy: 0.9257#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01547616/55000 [========================>.....] - ETA: 0s - loss: 0.2453 - accuracy: 0.9262#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01548160/55000 [=========================>....] - ETA: 0s - loss: 0.2439 - accuracy: 0.9265#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01548736/55000 [=========================>....] - ETA: 0s - loss: 0.2430 - accuracy: 0.9267#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01549312/55000 [=========================>....] - ETA: 0s - loss: 0.2423 - accuracy: 0.9269#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01549888/55000 [==========================>...] - ETA: 0s - loss: 0.2415 - accuracy: 0.9271#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01550464/55000 [==========================>...] - ETA: 0s - loss: 0.2403 - accuracy: 0.9275#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01551072/55000 [==========================>...] - ETA: 0s - loss: 0.2390 - accuracy: 0.9279#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01551648/55000 [===========================>..] - ETA\u001b[0m\n",
      "\u001b[34m: 0s - loss: 0.2381 - accuracy: 0.9281#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01552224/55000 [===========================>..] - ETA: 0s - loss: 0.2379 - accuracy: 0.9282#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01552800/55000 [===========================>..] - ETA: 0s - loss: 0.2368 - accuracy: 0.9285#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01553376/55000 [============================>.] - ETA: 0s - loss: 0.2355 - accuracy: 0.9288#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01553952/55000 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9290#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01554496/55000 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9293#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01555000/55000 [==============================] - 6s 111us/sample - loss: 0.2325 - accuracy: 0.9296\u001b[0m\n",
      "\u001b[34m#015   32/10000 [..............................] - ETA: 32s - loss: 0.0233 - accuracy: 1.0000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  576/10000 [>.............................] - ETA: 2s - loss: 0.0848 - accuracy: 0.9774 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1184/10000 [==>...........................] - ETA: 1s - loss: 0.1058 - accuracy: 0.9679#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 1888/10000 [====>.........................] - ETA: 1s - loss: 0.1353 - accuracy: 0.9640#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 2592/10000 [======>.......................] - ETA: 0s - loss: 0.1413 - accuracy: 0.9591#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3264/10000 [========>.....................] - ETA: 0s - loss: 0.1348 - accuracy: 0.9620#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 3936/10000 [==========>...................] - ETA: 0s - loss: 0.1380 - accuracy: 0.9601#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4640/10000 [============>.................] - ETA: 0s - loss: 0.1392 - accuracy: 0.9586#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 5312/10000 [==============>...............] - ETA: 0s - loss: 0.1343 - accuracy: 0.9603#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6016/10000 [=================>............] - ETA: 0s - loss: 0.1305 - accuracy: 0.9613#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 6720/10000 [===================>..........] - ETA: 0s - loss: 0.1265 - accuracy: 0.9625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7392/10000 [=====================>........] - ETA: 0s - loss: 0.1184 - accuracy: 0.9648#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8096/10000 [=======================>......] - ETA: 0s - loss: 0.1123 - accuracy: 0.9665#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 8768/10000 [=========================>....] - ETA: 0s - loss: 0.1063 - accuracy: 0.9683#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 9440/10000 [===========================>..] - ETA: 0s - loss: 0.1017 - accuracy: 0.9698#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01510000/10000 [==============================] - 1s 86us/sample - loss: 0.1041 - accuracy: 0.9690\u001b[0m\n",
      "\u001b[34m2020-04-11 21:27:26.910222: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\u001b[0m\n",
      "\u001b[34m[2020-04-11 21:27:27.202 ip-10-0-138-115.us-east-2.compute.internal:21 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:27:27,722 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-11 21:27:38 Uploading - Uploading generated training model\n",
      "2020-04-11 21:27:38 Completed - Training job completed\n",
      "Training seconds: 128\n",
      "Billable seconds: 128\n"
     ]
    }
   ],
   "source": [
    "tf_estimator = TensorFlow(\n",
    "    entry_point='../scripts/tensorflow_mnist.py',\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p2.xlarge',\n",
    "    framework_version='2.1.0',\n",
    "    py_version='py3',\n",
    "    enable_sagemaker_metrics=True)\n",
    "\n",
    "# Now associate the estimator with the Experiment and Trial\n",
    "tf_estimator.fit(\n",
    "    inputs={'training': training_data_uri}, \n",
    "    job_name=\"tensorflow-training-job-{}\".format(int(time.time())),\n",
    "    experiment_config={\n",
    "        \"TrialName\": trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"Training\",\n",
    "    },\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can view the `Experiment` metadata by clicking on the beaker icon in the vertical navigation bar on the left-side of your screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing Hyperparameter Search with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sagemaker.analytics import ExperimentAnalytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "We download the MNIST hand written digits dataset, and then apply transformation on each of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download, load, and transform the data.\n",
    "\n",
    "train_set = datasets.MNIST(LOCAL_DATA_DIRECTORY, train=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))]), \n",
    "    download=True)\n",
    "                           \n",
    "test_set = datasets.MNIST(LOCAL_DATA_DIRECTORY, train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHwCAYAAAC7cCafAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAb7klEQVR4nO3de7BsVX0n8O+Pi4LcEhBGJZYPHglQRaIENCiMyMMwmkTFCCn/iFIpTSUZZwhGp8wkkmDM1OjUVPBBBlNRQ0WrhmSwYpIJPkYBQTEayShhAqKBKzGKvML7oVzW/NH7muvJOffe09337HNWfz5VXev03nv1/rHd3m+v7t1rV2stAEA/9hi7AABgvoQ7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRmz7EL2B2q6uYk+ybZMnIpADCtg5Pc21o7ZLUduwz3JPvukU0HbM4TDxi7EACYxgO5L49l61R9ew33LZvzxAOOqxePXQcATOUL7VO5L3dvmabvqN+5V9XTq+qDVfWtqnqkqrZU1buq6klj1gUAG9loI/eqOizJ1UmekuTPk9yQ5CeS/GqSl1TVCa21O8eqDwA2qjFH7v8jk2A/u7V2emvt11trpyQ5P8kRSf7LiLUBwIY1SrhX1aFJTsvkavbfX7L6t5M8kOQ1VbV5jUsDgA1vrI/lTxnaT7bWHtt+RWvtvqr6XCbh//wkn17pRarqmhVWHTmXKgFgAxrrY/kjhvbGFdZ/bWgPX4NaAKArY43c9xvae1ZYv235/jt6kdbascstH0b0x0xXGgBsbOt1+tka2jZqFQCwAY0V7ttG5vutsH7fJdsBALtorHD/6tCu9J36jwztSt/JAwArGCvcLx/a06rqB2qoqicmOSHJQ0n+eq0LA4CNbpRwb639Q5JPZnLHmzcsWf22JJuT/HFr7YE1Lg0ANrwxbxzz7zOZfvY9VXVqkuuTHJfk5Ew+jv/NEWsDgA1rtKvlh9H7c5NclEmovynJYUnek+QF5pUHgOmMesvX1to/JvmFMWsAgN6s19+5AwBTEu4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCd2XPsAgDYdQ+ccdzUfd/53y6cad9v/7nXTt23fem6mfbN6ow2cq+qLVXVVnjcOlZdALDRjT1yvyfJu5ZZfv9aFwIAvRg73O9urZ03cg0A0BUX1AFAZ8Yeue9VVT+f5JlJHkhybZIrW2tbxy0LADauscP9oCQfWrLs5qr6hdbaZ3bWuaquWWHVkTNXBgAb1Jgfy/9RklMzCfjNSX4syR8kOTjJx6rqOeOVBgAb12gj99ba25Ysui7JL1fV/UnelOS8JK/cyWscu9zyYUR/zBzKBIANZz1eUPe+oT1x1CoAYINaj+F+29BuHrUKANig1mO4v2Bobxq1CgDYoEYJ96o6qqoOWGb5s5JcMDz98NpWBQB9GOuCujOT/HpVXZ7k5iT3JTksyU8n2TvJpUn++0i1AcCGNla4X57kiCQ/nsnH8JuT3J3ks5n87v1DrbU2Um0AsKGNEu7DBDU7naSG1XvoFT8xW/8DN03d94APfn6mfQM7d9tzp/829e1bXjbHSljP1uMFdQDADIQ7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ0a5nzu7z7dOnO392j6H3T195w/OtGtYDHtsmql7e+ZDU/c99Sk3zLTvT9fxM/Vn7Ri5A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdMYtXzvztp/5XzP1f+f1p82pEmA5mw571kz9b3jR9PdWPvqLPz/Tvp/2N383U3/WjpE7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHTG/dw787h6dOwSgB3Y8/0Pjrbvh/5h39H2zdoycgeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMW76uQ4/926On7vvCvT87x0qAeTt4852j7fsZn9o62r5ZW0buANCZuYR7VZ1RVe+tqquq6t6qalX14Z30Ob6qLq2qu6rqwaq6tqrOqapN86gJABbVvD6Wf2uS5yS5P8k3kxy5o42r6hVJPpLk4SR/kuSuJC9Lcn6SE5KcOae6AGDhzOtj+TcmOTzJvkl+ZUcbVtW+Sf4wydYkJ7XWXtda+09Jjk7y+SRnVNWr51QXACycuYR7a+3y1trXWmttFzY/I8mTk1zcWvvSdq/xcCafACQ7eYMAAKxsjAvqThnajy+z7sokDyY5vqr2WruSAKAfY/wU7oihvXHpitbao1V1c5Kjkhya5PodvVBVXbPCqh1+5w8APRtj5L7f0N6zwvpty/dfg1oAoDvrcRKbGtqdfn/fWjt22ReYjOiPmWdRALBRjDFy3zYy32+F9fsu2Q4AWIUxwv2rQ3v40hVVtWeSQ5I8muSmtSwKAHoxRrhfNrQvWWbdiUn2SXJ1a+2RtSsJAPoxRrhfkuSOJK+uquduW1hVeyf53eHphSPUBQBdmMsFdVV1epLTh6cHDe0Lquqi4e87WmtvTpLW2r1V9YuZhPwVVXVxJtPPvjyTn8ldksmUtADAFOZ1tfzRSc5asuzQ4ZEk30jy5m0rWmsfraoXJfnNJK9KsneSryf5tSTv2cWZ7gCAZcwl3Ftr5yU5b5V9Ppfkp+ax/95842eeMHXfp2zaZ46VAMvZ8+BnTt33jAP+Yo6VrM4Tbv7nmfq7G/zG4X7uANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnZnX/dyZoz1/+L7R9v3wDfuPtm/YKP7xXZun7nvCXo/NtO8P3Pv06Tvffe9M+2bjMHIHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM64nzs/4Clfmu1e07CrNv2bA2fq/51XHT513wN+7psz7fszh39ght57z7TvC3//9Kn7PuU7V8+0bzYOI3cA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOuOUrP+ChA6Z/v7d5jnWstcde+ONT922baqZ9/+OL95q673ef9r2Z9r3H47dO3feTL3zvTPt+3GyHLbdunf64nXvTK2fa912PTX9r5H32mP6YJ8lTv3Df1H3bTHtmIzFyB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOuJ/7OvTIw4+buu9jM96x+Y9+4/yp+/7Ffzh6pn2P6S0Hvn/qvntkthuTP9S+O3Xfb22d7d7gF9x+0tR9X/ypc2ba9/7/9/Ez9f+hT35n6r71jW/OtO/br3/C1H2fuul7M+27/c3fzdSfxWDkDgCdmUu4V9UZVfXeqrqqqu6tqlZVH15h24OH9Ss9Lp5HTQCwqOb1sfxbkzwnyf1JvpnkyF3o85UkH11m+XVzqgkAFtK8wv2NmYT615O8KMnlu9Dny6218+a0fwBgMJdwb619P8yrZru4CACYzZhXyz+tqn4pyYFJ7kzy+dbatat5gaq6ZoVVu/K1AAB0acxw/8nh8X1VdUWSs1prt4xSEQB0YIxwfzDJ2zO5mO6mYdmzk5yX5OQkn66qo1trD+zshVprxy63fBjRHzOXagFgg1nz37m31m5rrf1Wa+1vW2t3D48rk5yW5AtJfjjJ69e6LgDoxbqZxKa19miSbdOEnThmLQCwka2bcB/cPrSbR60CADaw9Rbuzx/am3a4FQCwojUP96o6rqr+1R0jquqUTCbDSZJlp64FAHZuLlfLV9XpSU4fnh40tC+oqouGv+9orb15+PudSY4afva27dZMz05yyvD3ua21q+dRFwAsonn9FO7oJGctWXbo8EiSbyTZFu4fSvLKJM9L8tIkj0vynSR/muSC1tpVc6oJABZStTbb/b/Xo6q65onZ/5jj6sVjl7Lmbv6vL5ip/zOe909zqmRx3P6xp8/U/8D/N/39vR//8b+Zad+L6p/ecvxM/b9y9gVT9734/ifPtO8/PuIZM/Vn4/hC+1Tuy91/u9KcLjuy3i6oAwBmJNwBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPzup8768Qh//nzY5ewcH4ot4xdAqu0z4m3j7bvt17+qpn6H54vzqkSembkDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdcT93gDX0rD9vY5fAAjByB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6MyeYxcAsNFsqunHRf98+ONm2vdBH5upOwti5pF7VR1YVa+vqj+rqq9X1UNVdU9VfbaqXle1/P8Lqur4qrq0qu6qqger6tqqOqeqNs1aEwAssnmM3M9McmGSbye5PMktSZ6a5GeTvD/JS6vqzNZa29ahql6R5CNJHk7yJ0nuSvKyJOcnOWF4TQBgCvMI9xuTvDzJX7XWHtu2sKp+I8kXk7wqk6D/yLB83yR/mGRrkpNaa18alp+b5LIkZ1TVq1trF8+hNgBYODN/LN9au6y19pfbB/uw/NYk7xuenrTdqjOSPDnJxduCfdj+4SRvHZ7+yqx1AcCi2t1Xy39vaB/dbtkpQ/vxZba/MsmDSY6vqr12Z2EA0KvddrV8Ve2Z5LXD0+2D/IihvXFpn9bao1V1c5Kjkhya5Pqd7OOaFVYdubpqAaAfu3Pk/o4kP5rk0tbaJ7Zbvt/Q3rNCv23L999dhQFAz3bLyL2qzk7ypiQ3JHnNarsPbdvhVklaa8eusP9rkhyzyv0CQBfmPnKvqjckeXeSv09ycmvtriWbbBuZ75fl7btkOwBgFeYa7lV1TpILklyXSbDfusxmXx3aw5fpv2eSQzK5AO+medYGAItibuFeVW/JZBKaL2cS7LetsOllQ/uSZdadmGSfJFe31h6ZV20AsEjmEu7DBDTvSHJNklNba3fsYPNLktyR5NVV9dztXmPvJL87PL1wHnUBwCKa+YK6qjorye9kMuPcVUnOrqqlm21prV2UJK21e6vqFzMJ+Suq6uJMpp99eSY/k7skkylpAYApzONq+UOGdlOSc1bY5jNJLtr2pLX20ap6UZLfzGR62r2TfD3JryV5z/bz0AMAqzNzuLfWzkty3hT9Ppfkp2bdP8Ba2/qDs22vzu6eFxTiNAOA7gh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzsx8P3cAdt2Dz3tw7BJYAEbuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnXHLV4BV2lTGRaxvzlAA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6Iz7uQML55FPPXmm/luPfmxOlcDuYeQOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGbd8BRbOQedfPVP/nzr/mKn7Hpovz7Rv2BVG7gDQmZnDvaoOrKrXV9WfVdXXq+qhqrqnqj5bVa+rqj2WbH9wVbUdPC6etSYAWGTz+Fj+zCQXJvl2ksuT3JLkqUl+Nsn7k7y0qs5srbUl/b6S5KPLvN51c6gJABbWPML9xiQvT/JXrbXHti2sqt9I8sUkr8ok6D+ypN+XW2vnzWH/AMB2Zv5YvrV2WWvtL7cP9mH5rUneNzw9adb9AAC7ZndfLf+9oX10mXVPq6pfSnJgkjuTfL61du1urgcAurfbwr2q9kzy2uHpx5fZ5CeHx/Z9rkhyVmvtll3cxzUrrDpyF8sEgO7szp/CvSPJjya5tLX2ie2WP5jk7UmOTfKk4fGiTC7GOynJp6tq826sCwC6tltG7lV1dpI3JbkhyWu2X9dauy3Jby3pcmVVnZbks0mOS/L6JO/e2X5aa8eusP9rkkw/ywQAbGBzH7lX1RsyCea/T3Jya+2uXenXWns0k5/OJcmJ864LABbFXMO9qs5JckEmv1U/ebhifjVuH1ofywPAlOYW7lX1liTnJ/lyJsF+2xQv8/yhvWledQHAoplLuFfVuZlcQHdNklNba3fsYNvjqurxyyw/Jckbh6cfnkddALCIZr6grqrOSvI7SbYmuSrJ2VW1dLMtrbWLhr/fmeSo4Wdv3xyWPTvJKcPf57bWZrtlEwAssHlcLX/I0G5Kcs4K23wmyUXD3x9K8sokz0vy0iSPS/KdJH+a5ILW2lVzqAkAFtbM4T7MD3/eKrb/QJIPzLpfAGB57ucOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ2p1trYNcxdVd25RzYdsDlPHLsUAJjKA7kvj2XrXa21A1fbd8/dUdA6cO9j2Zr7cveWFdYfObQ3rFE9PXDMpuO4TcdxWz3HbDrr+bgdnOTeaTp2OXLfmaq6Jklaa8eOXctG4ZhNx3GbjuO2eo7ZdHo9br5zB4DOCHcA6IxwB4DOCHcA6IxwB4DOLOTV8gDQMyN3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOjMQoV7VT29qj5YVd+qqkeqaktVvauqnjR2bevRcHzaCo9bx65vTFV1RlW9t6quqqp7h2Py4Z30Ob6qLq2qu6rqwaq6tqrOqapNa1X32FZz3Krq4B2cf62qLl7r+sdQVQdW1eur6s+q6utV9VBV3VNVn62q11XVsv+OL/r5ttrj1tv51uv93P+VqjosydVJnpLkzzO5d+9PJPnVJC+pqhNaa3eOWOJ6dU+Sdy2z/P61LmSdeWuS52RyHL6Zf7kn9LKq6hVJPpLk4SR/kuSuJC9Lcn6SE5KcuTuLXUdWddwGX0ny0WWWXzfHutazM5NcmOTbSS5PckuSpyb52STvT/LSqjqzbTcjmfMtyRTHbdDH+dZaW4hHkk8kaUn+45Llvzcsf9/YNa63R5ItSbaMXcd6fCQ5OcmPJKkkJw3n0IdX2HbfJLcleSTJc7dbvncmbzhbkleP/d+0Do/bwcP6i8aue+RjdkomwbzHkuUHZRJYLcmrtlvufJvuuHV1vi3Ex/JVdWiS0zIJq99fsvq3kzyQ5DVVtXmNS2ODaq1d3lr7Whv+VdiJM5I8OcnFrbUvbfcaD2cykk2SX9kNZa47qzxuJGmtXdZa+8vW2mNLlt+a5H3D05O2W+V8y1THrSuL8rH8KUP7yWX+h76vqj6XSfg/P8mn17q4dW6vqvr5JM/M5E3QtUmubK1tHbesDWXb+ffxZdZdmeTBJMdX1V6ttUfWrqwN42lV9UtJDkxyZ5LPt9auHbmm9eJ7Q/vodsucbzu33HHbpovzbVHC/YihvXGF9V/LJNwPj3Bf6qAkH1qy7Oaq+oXW2mfGKGgDWvH8a609WlU3JzkqyaFJrl/LwjaInxwe31dVVyQ5q7V2yygVrQNVtWeS1w5Ptw9y59sO7OC4bdPF+bYQH8sn2W9o71lh/bbl+69BLRvJHyU5NZOA35zkx5L8QSbfTX2sqp4zXmkbivNvOg8meXuSY5M8aXi8KJOLo05K8ukF/yrtHUl+NMmlrbVPbLfc+bZjKx23rs63RQn3namh9T3gdlprbxu+t/pOa+3B1tp1rbVfzuQixCckOW/cCrvh/FtGa+221tpvtdb+trV29/C4MpNP2b6Q5IeTvH7cKsdRVWcneVMmv/p5zWq7D+3CnW87Om69nW+LEu7b3qnut8L6fZdsx45tuxjlxFGr2Dicf3PUWns0k58yJQt4DlbVG5K8O8nfJzm5tXbXkk2cb8vYheO2rI16vi1KuH91aA9fYf2PDO1K38nzg24b2g3zEdXIVjz/hu//Dsnkwp6b1rKoDe72oV2oc7CqzklyQSa/uT55uPJ7KefbErt43HZkw51vixLulw/tacvMSvTETCZ1eCjJX691YRvUC4Z2Yf5xmNFlQ/uSZdadmGSfJFcv8JXL03j+0C7MOVhVb8lkEpovZxJQt62wqfNtO6s4bjuy4c63hQj31to/JPlkJheCvWHJ6rdl8m7sj1trD6xxaetWVR1VVQcss/xZmbwDTpIdTrfK912S5I4kr66q525bWFV7J/nd4emFYxS2nlXVcVX1+GWWn5LkjcPThTgHq+rcTC4EuybJqa21O3awufNtsJrj1tv5Vosyl8Qy089en+S4TGbMujHJ8c30s99XVecl+fVMPvW4Ocl9SQ5L8tOZzHR1aZJXtta+O1aNY6qq05OcPjw9KMm/y+Rd/VXDsjtaa29esv0lmUwHenEm04G+PJOfLV2S5OcWYWKX1Ry34edHRyW5IpOpapPk2fmX33Gf21rbFlbdqqqzklyUZGuS92b578q3tNYu2q7Pwp9vqz1u3Z1vY0+Rt5aPJM/I5Odd307y3STfyOQCiwPGrm29PTL5Ccj/zOSq0rszmfTh9iT/J5PfiNbYNY58fM7L5GrjlR5blulzQiZviv45k6+B/i6TEcGmsf971uNxS/K6JP87k5kl789kOtVbMpkr/YVj/7eso2PWklzhfJvtuPV2vi3MyB0AFsVCfOcOAItEuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHTm/wOsm2aui0JK8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_set.data[2].numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the images in the dataset, we upload it to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec: s3://sagemaker-workshop-420/mnist\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(\n",
    "    path=LOCAL_DATA_DIRECTORY,\n",
    "    bucket=BUCKET,\n",
    "    key_prefix=PREFIX)\n",
    "print(f'input spec: {inputs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets track the parameters from the data pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sagemaker_client) as tracker:\n",
    "    tracker.log_parameters({\n",
    "        \"normalization_mean\": 0.1307,\n",
    "        \"normalization_std\": 0.3081,\n",
    "    })\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"mnist-dataset\", media_type=\"s3/uri\", value=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment = Experiment.create(\n",
    "    experiment_name=f\"torch-mnist-classification-{int(time.time())}\", \n",
    "    description=\"Classification of mnist hand-written digits\", \n",
    "    sagemaker_boto_client=sagemaker_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f8f80d717d0>,experiment_name='torch-mnist-classification-1586640735',description='Classification of mnist hand-written digits',experiment_arn='arn:aws:sagemaker:us-east-2:209970524256:experiment/torch-mnist-classification-1586640735',response_metadata={'RequestId': '06f98b1e-9f49-4ae0-a790-0080573003a4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '06f98b1e-9f49-4ae0-a790-0080573003a4', 'content-type': 'application/x-amz-json-1.1', 'content-length': '109', 'date': 'Sat, 11 Apr 2020 21:32:15 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "print(mnist_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment\n",
    "\n",
    "While training the CNN model on SageMaker, we will experiment with several values for the number of hidden channel in the model. We will create a Trial to track each training job run. We will also create a TrialComponent from the tracker we created before, and add to the Trial. This will enrich the Trial with the parameters we captured from the data pre-processing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-pytorch-2020-04-11-21-35-04-730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 21:35:05 Starting - Starting the training job...\n",
      "2020-04-11 21:35:07 Starting - Launching requested ML instances......\n",
      "2020-04-11 21:36:29 Starting - Preparing the instances for training......\n",
      "2020-04-11 21:37:09 Downloading - Downloading input data...\n",
      "2020-04-11 21:37:52 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:53,777 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:53,780 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:53,793 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:54,017 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:54,266 sagemaker-containers INFO     Module pytorch_mnist does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:54,266 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:54,267 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:54,267 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pytorch-mnist\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for pytorch-mnist: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jo6g2igf/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built pytorch-mnist\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytorch-mnist\u001b[0m\n",
      "\u001b[34mSuccessfully installed pytorch-mnist-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:56,015 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 21:37:56,027 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"optimizer\": \"sgd\",\n",
      "        \"hidden_channels\": 2,\n",
      "        \"dropout\": 0.2,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-04-11-21-35-04-730\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-35-04-730/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pytorch_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pytorch_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":2,\"optimizer\":\"sgd\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pytorch_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pytorch_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-35-04-730/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":2,\"optimizer\":\"sgd\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-04-11-21-35-04-730\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-35-04-730/source/sourcedir.tar.gz\",\"module_name\":\"pytorch_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pytorch_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--dropout\",\"0.2\",\"--epochs\",\"2\",\"--hidden_channels\",\"2\",\"--optimizer\",\"sgd\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=sgd\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_CHANNELS=2\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pytorch_mnist --backend gloo --dropout 0.2 --epochs 2 --hidden_channels 2 --optimizer sgd\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 60000/60000 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/60000 (11%)], Train Loss: 1.617049;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)], Train Loss: 0.941270;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/60000 (32%)], Train Loss: 0.843992;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)], Train Loss: 0.432059;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)], Train Loss: 0.464780;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)], Train Loss: 0.322854;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/60000 (75%)], Train Loss: 0.351526;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)], Train Loss: 0.389307;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [57600/60000 (96%)], Train Loss: 0.375780;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1852, Test Accuracy: 95%;\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/60000 (11%)], Train Loss: 0.275706;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)], Train Loss: 0.292543;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/60000 (32%)], Train Loss: 0.244455;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)], Train Loss: 0.283167;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/60000 (53%)], Train Loss: 0.279576;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)], Train Loss: 0.341436;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/60000 (75%)], Train Loss: 0.414407;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)], Train Loss: 0.193495;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [57600/60000 (96%)], Train Loss: 0.157259;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1158, Test Accuracy: 97%;\n",
      "\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:38:36,814 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-11 21:38:45 Uploading - Uploading generated training model\n",
      "2020-04-11 21:38:45 Completed - Training job completed\n",
      "Training seconds: 96\n",
      "Billable seconds: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-pytorch-2020-04-11-21-39-20-091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 21:39:20 Starting - Starting the training job...\n",
      "2020-04-11 21:39:21 Starting - Launching requested ML instances...\n",
      "2020-04-11 21:40:16 Starting - Preparing the instances for training......\n",
      "2020-04-11 21:41:06 Downloading - Downloading input data...\n",
      "2020-04-11 21:41:46 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:47,222 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:47,225 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:47,236 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:47,459 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:47,696 sagemaker-containers INFO     Module pytorch_mnist does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:47,696 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:47,696 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:47,696 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pytorch-mnist\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: started\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mjru6xln/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built pytorch-mnist\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytorch-mnist\u001b[0m\n",
      "\u001b[34mSuccessfully installed pytorch-mnist-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:49,315 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 21:41:49,327 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"optimizer\": \"sgd\",\n",
      "        \"hidden_channels\": 5,\n",
      "        \"dropout\": 0.2,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-04-11-21-39-20-091\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-39-20-091/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pytorch_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pytorch_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":5,\"optimizer\":\"sgd\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pytorch_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pytorch_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-39-20-091/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":5,\"optimizer\":\"sgd\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-04-11-21-39-20-091\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-39-20-091/source/sourcedir.tar.gz\",\"module_name\":\"pytorch_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pytorch_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--dropout\",\"0.2\",\"--epochs\",\"2\",\"--hidden_channels\",\"5\",\"--optimizer\",\"sgd\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=sgd\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_CHANNELS=5\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pytorch_mnist --backend gloo --dropout 0.2 --epochs 2 --hidden_channels 5 --optimizer sgd\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 60000/60000 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/60000 (11%)], Train Loss: 1.698200;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)], Train Loss: 0.994831;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/60000 (32%)], Train Loss: 0.611539;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)], Train Loss: 0.648925;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)], Train Loss: 0.571486;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)], Train Loss: 0.791933;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/60000 (75%)], Train Loss: 0.438099;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)], Train Loss: 0.549112;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [57600/60000 (96%)], Train Loss: 0.480673;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1914, Test Accuracy: 94%;\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/60000 (11%)], Train Loss: 0.297167;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)], Train Loss: 0.364907;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/60000 (32%)], Train Loss: 0.268553;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)], Train Loss: 0.272427;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/60000 (53%)], Train Loss: 0.382764;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)], Train Loss: 0.482188;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/60000 (75%)], Train Loss: 0.203590;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)], Train Loss: 0.445356;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [57600/60000 (96%)], Train Loss: 0.197844;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1157, Test Accuracy: 96%;\n",
      "\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:42:31,298 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-11 21:42:39 Uploading - Uploading generated training model\n",
      "2020-04-11 21:42:39 Completed - Training job completed\n",
      "Training seconds: 93\n",
      "Billable seconds: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-pytorch-2020-04-11-21-43-04-167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 21:43:04 Starting - Starting the training job...\n",
      "2020-04-11 21:43:05 Starting - Launching requested ML instances...\n",
      "2020-04-11 21:44:02 Starting - Preparing the instances for training......\n",
      "2020-04-11 21:45:04 Downloading - Downloading input data\n",
      "2020-04-11 21:45:04 Training - Downloading the training image...\n",
      "2020-04-11 21:45:18 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:19,076 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:19,078 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:19,091 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:22,115 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:22,391 sagemaker-containers INFO     Module pytorch_mnist does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:22,392 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:22,392 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:22,392 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pytorch-mnist\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: started\n",
      "  Running setup.py bdist_wheel for pytorch-mnist: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-efoh3z64/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built pytorch-mnist\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytorch-mnist\u001b[0m\n",
      "\u001b[34mSuccessfully installed pytorch-mnist-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:24,074 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-11 21:45:24,087 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"optimizer\": \"sgd\",\n",
      "        \"hidden_channels\": 10,\n",
      "        \"dropout\": 0.2,\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-04-11-21-43-04-167\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-43-04-167/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pytorch_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pytorch_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":10,\"optimizer\":\"sgd\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pytorch_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pytorch_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-43-04-167/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"dropout\":0.2,\"epochs\":2,\"hidden_channels\":10,\"optimizer\":\"sgd\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-04-11-21-43-04-167\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-209970524256/sagemaker-pytorch-2020-04-11-21-43-04-167/source/sourcedir.tar.gz\",\"module_name\":\"pytorch_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pytorch_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--dropout\",\"0.2\",\"--epochs\",\"2\",\"--hidden_channels\",\"10\",\"--optimizer\",\"sgd\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=sgd\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_CHANNELS=10\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pytorch_mnist --backend gloo --dropout 0.2 --epochs 2 --hidden_channels 10 --optimizer sgd\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 60000/60000 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/60000 (11%)], Train Loss: 1.695285;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)], Train Loss: 0.928432;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/60000 (32%)], Train Loss: 0.702160;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)], Train Loss: 0.442871;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)], Train Loss: 0.413667;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)], Train Loss: 0.501132;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/60000 (75%)], Train Loss: 0.383585;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)], Train Loss: 0.328490;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [57600/60000 (96%)], Train Loss: 0.396089;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1679, Test Accuracy: 95%;\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/60000 (11%)], Train Loss: 0.603119;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)], Train Loss: 0.229334;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/60000 (32%)], Train Loss: 0.281790;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)], Train Loss: 0.376957;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/60000 (53%)], Train Loss: 0.412861;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)], Train Loss: 0.200810;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/60000 (75%)], Train Loss: 0.233049;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)], Train Loss: 0.319483;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [57600/60000 (96%)], Train Loss: 0.210030;\u001b[0m\n",
      "\u001b[34mTest Average loss: 0.1060, Test Accuracy: 97%;\n",
      "\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2020-04-11 21:46:13,093 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-11 21:46:21 Uploading - Uploading generated training model\n",
      "2020-04-11 21:46:21 Completed - Training job completed\n",
      "Training seconds: 102\n",
      "Billable seconds: 102\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Keep references to each Trial object\n",
    "hidden_channel_trial_name_map = {}\n",
    "preprocessing_trial_component = tracker.trial_component\n",
    "\n",
    "# If you want to run the following training jobs asynchronously, you may need to increase\n",
    "# your resource limit. Otherwise, you can run them sequentially.\n",
    "for i, num_hidden_channel in enumerate([2, 5, 10]):\n",
    "    \n",
    "    # create Trial oobject\n",
    "    trial_name = f\"cnn-training-job-{num_hidden_channel}-hidden-channels-{int(time.time())}\"\n",
    "    cnn_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "        experiment_name=mnist_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sagemaker_client,\n",
    "    )\n",
    "    hidden_channel_trial_name_map[num_hidden_channel] = trial_name\n",
    "    \n",
    "    # Associate the proprocessing trial component with the current trial\n",
    "    cnn_trial.add_trial_component(preprocessing_trial_component)\n",
    "    \n",
    "    # all input configurations, parameters, and metrics specified in estimator \n",
    "    # definition are automatically tracked\n",
    "    estimator = PyTorch(\n",
    "        entry_point='../scripts/pytorch_mnist.py',\n",
    "        role=role,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        framework_version='1.1.0',\n",
    "        train_instance_count=1,\n",
    "        train_instance_type='ml.c4.xlarge',\n",
    "        hyperparameters={\n",
    "            'epochs': 2,\n",
    "            'backend': 'gloo',\n",
    "            'hidden_channels': num_hidden_channel,\n",
    "            'dropout': 0.2,\n",
    "            'optimizer': 'sgd'\n",
    "        },\n",
    "        metric_definitions=[\n",
    "            {'Name':'train:loss', 'Regex':'Train Loss: (.*?);'},\n",
    "            {'Name':'test:loss', 'Regex':'Test Average loss: (.*?),'},\n",
    "            {'Name':'test:accuracy', 'Regex':'Test Accuracy: (.*?)%;'}\n",
    "        ],\n",
    "        enable_sagemaker_metrics=True,\n",
    "    )\n",
    "    \n",
    "    # Now associate the estimator with the Experiment and Trial\n",
    "    estimator.fit(\n",
    "        inputs={'training': inputs}, \n",
    "        experiment_config={\n",
    "            \"TrialName\": cnn_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "        wait=True,\n",
    "    )\n",
    "    \n",
    "    # give it a while before dispatching the next training job\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the model training runs for an experiment\n",
    "\n",
    "Now we will use the analytics capabilities of Python SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Simple Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\":[\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    experiment_name=mnist_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.test:accuracy.max\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=['test:accuracy'],\n",
    "    parameter_names=['hidden_channels', 'epochs', 'dropout', 'optimizer']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>test:accuracy - Min</th>\n",
       "      <th>test:accuracy - Max</th>\n",
       "      <th>test:accuracy - Avg</th>\n",
       "      <th>test:accuracy - StdDev</th>\n",
       "      <th>test:accuracy - Last</th>\n",
       "      <th>test:accuracy - Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sagemaker-pytorch-2020-04-11-21-43-04-167-aws-...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:209970524256:train...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"sgd\"</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sagemaker-pytorch-2020-04-11-21-35-04-730-aws-...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:209970524256:train...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"sgd\"</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sagemaker-pytorch-2020-04-11-21-39-20-091-aws-...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:209970524256:train...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>\"sgd\"</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName DisplayName  \\\n",
       "0  sagemaker-pytorch-2020-04-11-21-43-04-167-aws-...    Training   \n",
       "1  sagemaker-pytorch-2020-04-11-21-35-04-730-aws-...    Training   \n",
       "2  sagemaker-pytorch-2020-04-11-21-39-20-091-aws-...    Training   \n",
       "\n",
       "                                           SourceArn  dropout  epochs  \\\n",
       "0  arn:aws:sagemaker:us-east-2:209970524256:train...      0.2     2.0   \n",
       "1  arn:aws:sagemaker:us-east-2:209970524256:train...      0.2     2.0   \n",
       "2  arn:aws:sagemaker:us-east-2:209970524256:train...      0.2     2.0   \n",
       "\n",
       "   hidden_channels optimizer  test:accuracy - Min  test:accuracy - Max  \\\n",
       "0             10.0     \"sgd\"                 95.0                 97.0   \n",
       "1              2.0     \"sgd\"                 95.0                 97.0   \n",
       "2              5.0     \"sgd\"                 94.0                 96.0   \n",
       "\n",
       "   test:accuracy - Avg  test:accuracy - StdDev  test:accuracy - Last  \\\n",
       "0                 96.0                1.414214                  97.0   \n",
       "1                 96.0                1.414214                  97.0   \n",
       "2                 95.0                1.414214                  96.0   \n",
       "\n",
       "   test:accuracy - Count  \n",
       "0                      2  \n",
       "1                      2  \n",
       "2                      2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To isolate and measure the impact of change in hidden channels on model accuracy, we vary the number of hidden channel and fix the value for other hyperparameters.\n",
    "\n",
    "Next let's look at an example of tracing the lineage of a model by accessing the data tracked by SageMaker Experiments for `cnn-training-job-2-hidden-channels` trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    search_expression={\n",
    "        \"Filters\":[{\n",
    "            \"Name\": \"Parents.TrialName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": hidden_channel_trial_name_map[2]\n",
    "        }]\n",
    "    },\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>normalization_mean</th>\n",
       "      <th>normalization_std</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>backend</th>\n",
       "      <th>...</th>\n",
       "      <th>test:accuracy - Avg</th>\n",
       "      <th>test:accuracy - StdDev</th>\n",
       "      <th>test:accuracy - Last</th>\n",
       "      <th>test:accuracy - Count</th>\n",
       "      <th>train:loss - Min</th>\n",
       "      <th>train:loss - Max</th>\n",
       "      <th>train:loss - Avg</th>\n",
       "      <th>train:loss - StdDev</th>\n",
       "      <th>train:loss - Last</th>\n",
       "      <th>train:loss - Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrialComponent-2020-04-11-213157-tnjl</td>\n",
       "      <td>Preprocessing</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.3081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sagemaker-pytorch-2020-04-11-21-35-04-730-aws-...</td>\n",
       "      <td>Training</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>arn:aws:sagemaker:us-east-2:209970524256:train...</td>\n",
       "      <td>520713654638.dkr.ecr.us-east-2.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c4.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"gloo\"</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.157259</td>\n",
       "      <td>1.617049</td>\n",
       "      <td>0.456703</td>\n",
       "      <td>0.352488</td>\n",
       "      <td>0.157259</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName    DisplayName  \\\n",
       "0              TrialComponent-2020-04-11-213157-tnjl  Preprocessing   \n",
       "1  sagemaker-pytorch-2020-04-11-21-35-04-730-aws-...       Training   \n",
       "\n",
       "   normalization_mean  normalization_std  \\\n",
       "0              0.1307             0.3081   \n",
       "1                 NaN                NaN   \n",
       "\n",
       "                                           SourceArn  \\\n",
       "0                                                NaN   \n",
       "1  arn:aws:sagemaker:us-east-2:209970524256:train...   \n",
       "\n",
       "                                  SageMaker.ImageUri  SageMaker.InstanceCount  \\\n",
       "0                                                NaN                      NaN   \n",
       "1  520713654638.dkr.ecr.us-east-2.amazonaws.com/s...                      1.0   \n",
       "\n",
       "  SageMaker.InstanceType  SageMaker.VolumeSizeInGB backend  ...  \\\n",
       "0                    NaN                       NaN     NaN  ...   \n",
       "1           ml.c4.xlarge                      30.0  \"gloo\"  ...   \n",
       "\n",
       "   test:accuracy - Avg  test:accuracy - StdDev  test:accuracy - Last  \\\n",
       "0                  NaN                     NaN                   NaN   \n",
       "1                 96.0                1.414214                  97.0   \n",
       "\n",
       "  test:accuracy - Count  train:loss - Min train:loss - Max train:loss - Avg  \\\n",
       "0                   NaN               NaN              NaN              NaN   \n",
       "1                   2.0          0.157259         1.617049         0.456703   \n",
       "\n",
       "  train:loss - StdDev train:loss - Last train:loss - Count  \n",
       "0                 NaN               NaN                NaN  \n",
       "1            0.352488          0.157259               18.0  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineage_table.dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:environment/datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
